{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b8785b3b2c343b1ae0107d791becbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_857bed062fe2468da9a5979c31f4f759",
              "IPY_MODEL_1c46951fc57d4075a8af2508cabf5b79",
              "IPY_MODEL_6d5ecbd5ec3d4fdb9138e31cd1f4fe3d"
            ],
            "layout": "IPY_MODEL_58c24a2ad9954d218a1c3fac82293401"
          }
        },
        "857bed062fe2468da9a5979c31f4f759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5d59b9065e48ecbbdb040e7dfeabb0",
            "placeholder": "​",
            "style": "IPY_MODEL_8650ae0a68d6402e92e9c5d174789d6d",
            "value": "100%"
          }
        },
        "1c46951fc57d4075a8af2508cabf5b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045e7d8b2dcc461cb73cb895d7e5841e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ac935c870624b2f862b42b7c5ee16af",
            "value": 2
          }
        },
        "6d5ecbd5ec3d4fdb9138e31cd1f4fe3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b8853c859e4ef0b7f418595dc65f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_de1001c678e94b449faf7bcb69c73623",
            "value": " 2/2 [00:00&lt;00:00, 30.72it/s]"
          }
        },
        "58c24a2ad9954d218a1c3fac82293401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d5d59b9065e48ecbbdb040e7dfeabb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8650ae0a68d6402e92e9c5d174789d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "045e7d8b2dcc461cb73cb895d7e5841e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac935c870624b2f862b42b7c5ee16af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1b8853c859e4ef0b7f418595dc65f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1001c678e94b449faf7bcb69c73623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiantonelli/DeepLearning-Project/blob/main/Deep_Learning_Project_Antonelli_Cuconasu_Gaudenzi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "_0HXoR9RpcO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxGf0hOgnsPD",
        "outputId": "fa49b631-ccea-4f4e-c7e8-93de12beff76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.2/826.2 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet"
      ],
      "metadata": {
        "id": "Pz3t2V0ClWo7",
        "outputId": "0b5be348-f5f1-459b-dcb8-41aaeb1db758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset"
      ],
      "metadata": {
        "id": "SPDaJczCk5tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = list_datasets()"
      ],
      "metadata": {
        "id": "4aJ_ii0Nm-sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_dataset = list_datasets(with_details=True)[datasets.index('math_dataset')]"
      ],
      "metadata": {
        "id": "nRUacuHwnA3q",
        "outputId": "725fa90d-d67c-44e8-dfdb-955e9d74d211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_deprecation.py:233: FutureWarning: 'list_datasets' currently returns a list of objects but is planned to be a generator starting from version 0.14 in order to implement pagination. Please avoid to use `list_datasets(...).__getitem__` or explicitly convert the output to a list first with `list(iter(list_datasets)(...))`.\n",
            "  warnings.warn(self._deprecation_msg.format(attr_name=attr_name), FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#math_dataset"
      ],
      "metadata": {
        "id": "ll5l6PL7neap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_examples, test_examples = load_dataset('math_dataset/arithmetic__mul', split=['train', 'test'], as_supervised=True)\n",
        "dataset = load_dataset('math_dataset', 'algebra__linear_1d')"
      ],
      "metadata": {
        "id": "Zwjeue58lk3r",
        "outputId": "b1df7ebd-d029-49d8-f8df-bcd60983221e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "9b8785b3b2c343b1ae0107d791becbea",
            "857bed062fe2468da9a5979c31f4f759",
            "1c46951fc57d4075a8af2508cabf5b79",
            "6d5ecbd5ec3d4fdb9138e31cd1f4fe3d",
            "58c24a2ad9954d218a1c3fac82293401",
            "4d5d59b9065e48ecbbdb040e7dfeabb0",
            "8650ae0a68d6402e92e9c5d174789d6d",
            "045e7d8b2dcc461cb73cb895d7e5841e",
            "0ac935c870624b2f862b42b7c5ee16af",
            "e1b8853c859e4ef0b7f418595dc65f2d",
            "de1001c678e94b449faf7bcb69c73623"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset math_dataset (/root/.cache/huggingface/datasets/math_dataset/algebra__linear_1d/1.0.0/55e25f9e337098b6760efcf2bbc1c0c9a11d94266b33ad3435bfdcd25aff0377)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b8785b3b2c343b1ae0107d791becbea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = dataset['train'], dataset['test']"
      ],
      "metadata": {
        "id": "NihXhDl0qlpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in train:\n",
        "    print(q)"
      ],
      "metadata": {
        "id": "fMip25MEqySw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle as pkl\n",
        "from tqdm.notebook import tqdm\n",
        "import pytorch_lightning as pl \n",
        "import math\n",
        "from math import sqrt\n",
        "import pickle\n",
        "from typing import *"
      ],
      "metadata": {
        "id": "DobcczcWqek-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "P4AfeDpYq3dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNGXDrHt71Y",
        "outputId": "a824da41-c4a9-4086-814e-21630048fc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/DeepLearningProject-Shared\"\n",
        "os.chdir(dataset_folder_path)"
      ],
      "metadata": {
        "id": "gDIk7qc1uP4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmbglL0Yt7yu",
        "outputId": "319ce248-16c6-41b1-c185-48214a119e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algebra__linear_1d  mathematics_dataset-v1.0  modules.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ve_GZkJh8TAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    with open(text_path) as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            if lowercase:\n",
        "                if idx % 2 == 0: # Questions\n",
        "                    questions.append(line.rstrip().lower()) \n",
        "                else:\n",
        "                    answers.append(line.rstrip().lower())\n",
        "\n",
        "    return questions, answers"
      ],
      "metadata": {
        "id": "8v1Y18AQt7wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(lists_of_texts: List[List[str]]):\n",
        "    unified_text = []\n",
        "    \n",
        "    for l in lists_of_texts:\n",
        "        unified_text += l\n",
        "\n",
        "    return Counter(\" \".join(unified_text)).keys()"
      ],
      "metadata": {
        "id": "lYe9h3nL2ef0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "# Get all files\n",
        "folders = ['extrapolate', 'interpolate', 'train-easy', 'train-medium', 'train-hard']\n",
        "files = []\n",
        "\n",
        "for fold in folders:\n",
        "    files += glob.glob(f\"./mathematics_dataset-v1.0/{fold}/*.txt\")"
      ],
      "metadata": {
        "id": "0dvxsrOv8jev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ8XDzZhDqiy",
        "outputId": "f71095af-44fa-49e3-8990-5653475f42d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./mathematics_dataset-v1.0/extrapolate/arithmetic__add_sub_multiple_longer.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/algebra__polynomial_roots_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__add_or_sub_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__div_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__mul_div_multiple_longer.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {}\n",
        "all_lists = []"
      ],
      "metadata": {
        "id": "6STsKEUWF3Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for f in files:\n",
        "    train, test = read_dataset(f)\n",
        "    all_lists += train\n",
        "    all_lists += test\n",
        "\n",
        "    vocabulary = vocabulary | get_vocabulary(all_lists)\n",
        "    all_lists = []\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        with open('./datasets/vocabulary.pkl', 'wb') as f:\n",
        "            pickle.dump(vocabulary, f)"
      ],
      "metadata": {
        "id": "FUejIWdZGnPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary"
      ],
      "metadata": {
        "id": "BQ2P_Vw3HKkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./datasets/vocabulary.pkl', 'rb') as f:\n",
        "    v = pickle.load(f)"
      ],
      "metadata": {
        "id": "jM-I-ODQOcUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary"
      ],
      "metadata": {
        "id": "A9Hzt8oUOjBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SWv7XaOEGqJ",
        "outputId": "8268c4f7-7c66-495b-ad88-4b3c302ee7ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_lists)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr-Lz5ndDvTW",
        "outputId": "63ec9f4a-a2bc-4074-d2e6-6693b8b0fdc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algebra_path = \"./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt\"\n",
        "probability_path = \"./mathematics_dataset-v1.0/train-easy/probability__swr_p_level_set.txt\"\n",
        "prime_path = \"./mathematics_dataset-v1.0/train-easy/numbers__is_prime.txt\""
      ],
      "metadata": {
        "id": "NubFUsQo0TM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_easy_algebra, answers_easy_algebra = read_dataset(algebra_path)\n",
        "questions_easy_probability, answers_easy_probability = read_dataset(probability_path)\n",
        "questions_easy_prime, answers_easy_prime = read_dataset(prime_path)"
      ],
      "metadata": {
        "id": "qfOfAYIh08FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "lis = \" \".join(questions_easy_prime)\n",
        "Counter(lis)"
      ],
      "metadata": {
        "id": "vkIbTIzAyPQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = []\n",
        "a = questions_easy_algebra + answers_easy_algebra"
      ],
      "metadata": {
        "id": "WFzzrWrL3Fx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[-4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9i8rzuUO3K3q",
        "outputId": "b8c6eca7-b149-4d88-9c32-565731fccabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = get_vocabulary([questions_easy_algebra, answers_easy_algebra])"
      ],
      "metadata": {
        "id": "qLdQ5Ub64D19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8-fBTK96BjC",
        "outputId": "9dc23cc9-c6e4-44a5-b933-7b4688e05e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['s', 'o', 'l', 'v', 'e', ' ', '0', '=', '4', '*', 'b', '+', '1', '5', 'f', 'r', '.', '-', '3', 'd', 'h', '9', '2', 'm', '8', '7', 'a', '6', 'w', 'c', 'z', 'j', 'n', 'y', 'x', 'u', 'g', 'k', 'q', 'i', 'p', 't'])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "a = string.printable"
      ],
      "metadata": {
        "id": "ReFssKsb4S9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.ascii_uppercase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SrE81tMC6X0Y",
        "outputId": "761502c0-830e-4d62-f4d3-381212fbbe6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(string.ascii_lowercase) + 10 + ['%', '&', '(', ')', ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7cY2Ch5uV2",
        "outputId": "80982439-bc49-49af-fa11-3c980f9ee57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NsdZzFFW5Igb",
        "outputId": "6f14df05-e5b5-4e75-e032-8492f69c2072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8tMm3aIe5ESf",
        "outputId": "085ad29a-775b-42e4-9f6b-5b99233a2752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(a[:-6]) - len(string.ascii_uppercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1V_7Duz4JiO",
        "outputId": "9b6d470c-d176-4b66-b1af-57e02a9d2e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#insert <bos>, <eos> and <pad>\n",
        "it = 0\n",
        "questions, answers = [], []\n",
        "seq_len = 256\n",
        "answer_len = 50\n",
        "for qa in train:\n",
        "    q = qa['question']\n",
        "    a = qa['answer']\n",
        "    question = ['<bos>']\n",
        "    answer = ['<bos>']\n",
        "    for i in range(1, len(q) - 1):\n",
        "        question.append(q[i])\n",
        "    while i < seq_len - 1:\n",
        "        question.append('<pad>')\n",
        "        i += 1\n",
        "    question.append('<eos>')\n",
        "    questions.append(question)\n",
        "    for j in range(1, len(a) - 1):\n",
        "        answer.append(a[j])\n",
        "    while j < answer_len - 1:\n",
        "        answer.append('<pad>')\n",
        "        j += 1\n",
        "    answer.append('<eos>')\n",
        "    answers.append(answer)\n",
        "    it += 1\n",
        "    if it % 10000 == 0:\n",
        "        print(f\"iteration {it}\")"
      ],
      "metadata": {
        "id": "FOKF8rS40H5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize"
      ],
      "metadata": {
        "id": "jTr3UUzxtsvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train"
      ],
      "metadata": {
        "id": "Dae9QoHz2Kik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions[:5]"
      ],
      "metadata": {
        "id": "Ejt881Sw2kn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "ho9Tk3GctrvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#forse meglio definire una stable softmax"
      ],
      "metadata": {
        "id": "tg6p4Y4ZXAyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product_attention(query, key, value, sqrt_q, device, mask = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    if mask is not None:\n",
        "      t = t.masked_fill_(mask == 0, -1e-10) #-1e-10 acts like -infinity, so that the softmax will consider these tokens less important\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)"
      ],
      "metadata": {
        "id": "9JbWbeOJtt02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module): \n",
        "    def __init__(self, d, num_heads, batch_size):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d % num_heads == 0\n",
        "        self.dim_head = d // num_heads #single head dimension\n",
        "        self.sqrt_q = sqrt(self.dim_head)\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.W_q = nn.Linear(d, d, bias = False) #stack of num_heads matrices of dimension (d, dim_head), one for each head\n",
        "        self.W_k = nn.Linear(d, d, bias = False)\n",
        "        self.W_v = nn.Linear(d, d, bias = False)\n",
        "        self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None): #query, key, value\n",
        "        query = self.W_q(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        key = self.W_k(key).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        value = self.W_v(value).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        attention_value = dot_product_attention(query, key, value, self.sqrt_q, mask)\n",
        "        return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.num_heads*self.dim_head))"
      ],
      "metadata": {
        "id": "cdtptdthS6Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TP_MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d, num_heads, batch_size):\n",
        "        super(TP_MultiHeadAttention, self).__init__()\n",
        "        assert d % num_heads == 0\n",
        "        self.dim_head = d // num_heads #single head dimension\n",
        "        self.sqrt_q = sqrt(self.dim_head)\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.W_q = nn.Linear(d, d, bias = True) #stack of num_heads matrices of dimension (d, dim_head), one for each head\n",
        "        self.W_k = nn.Linear(d, d, bias = True)\n",
        "        self.W_v = nn.Linear(d, d, bias = True)\n",
        "        self.W_o = nn.Linear(d, d, bias = True)\n",
        "        self.W_r = nn.Linear(d, d, bias = True) #ruolo\n",
        "\n",
        "    def forward(self, query, key, value, mask = None): #query, key, value\n",
        "        pass"
      ],
      "metadata": {
        "id": "lEUjRO5EURve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d, num_heads, batch_size, hidden_size, dropout = 0.2, tp_attention = False):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.d = d\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.attention = MultiHeadAttention(d, num_heads, batch_size) if not tp_attention else TP_MultiHeadAttention(d, num_heads, batch_size)\n",
        "        self.norm1 = nn.LayerNorm(d)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.norm2 = nn.LayerNorm(d)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.ff = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                                nn.ReLU(inplace = True),\n",
        "                                nn.Linear(hidden_size, d, bias = True))\n",
        "\n",
        "    def forward(self, query, key, value, mask = None): #query, key, value\n",
        "        x = query + self.attention(query, key, value, mask) #query as res conn because the decoder block requires it and it doesn't matter for encoder blocks\n",
        "        x = self.dropout1(self.norm1(x))\n",
        "        x = x + self.ff(x)\n",
        "        x = self.dropout2(self.norm2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhrmQH8sUHwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d, num_heads, batch_size, hidden_size, dropout = 0.2, tp_attention = False):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d, num_heads, batch_size) if not tp_attention else TP_MultiHeadAttention(d, num_heads, batch_size)\n",
        "        self.norm = nn.LayerNorm(d)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.transformer_block = TransformerBlock(d, num_heads, batch_size, hidden_size, dropout, tp_attention)\n",
        "\n",
        "    def forward(self, query, key, value, output_encoder, mask):\n",
        "        x = query + self.attention(query, key, value, mask) #masked attention + residual connection\n",
        "        x = self.dropout(self.norm(x))\n",
        "        return self.transformer_block(x, output_encoder, output_encoder)#query from the masked mha and key and value from the encoder"
      ],
      "metadata": {
        "id": "w0MIvv-ZWL-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d, max_len = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d, 2) * -(math.log(10000.0) / d))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x + Variable(self.pe[:, :x.size(1)], requires_grad = False)"
      ],
      "metadata": {
        "id": "qrsDFyoyUF0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, d, num_heads, batch_size, hidden_size, dropout, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d = d\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = nn.ModuleList(\n",
        "            [TransformerBlock(d, num_heads, batch_size, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, x): \n",
        "        for block in self.encoder:\n",
        "            x = block(x, x, x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bgNDRuG5YIWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, d, num_heads, batch_size, hidden_size, dropout = 0.2, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d = d\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.decoder = nn.ModuleList(\n",
        "            [DecoderBlock(d, num_heads, batch_size, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, x, output_encoder, mask): \n",
        "        for block in self.decoder:\n",
        "            x = block(x, x, x, output_encoder, mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Aybtz4uUY8vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, d, num_heads, batch_size, hidden_size, dropout, num_blocks_encoder = 6, num_blocks_decoder = 6, tp_attention = False):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d = d\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        #self.token_embedding = nn.Embedding()\n",
        "        #self.positional_embedding = PositionalEncoding()\n",
        "        self.encoder = TransformerEncoder(d, num_heads, batch_size, hidden_size, dropout, num_blocks_encoder, tp_attention)\n",
        "        self.decoder = TransformerDecoder(d, num_heads, batch_size, hidden_size, dropout, num_blocks_decoder, tp_attention)\n",
        "\n",
        "    #creazione maschere da fare\n",
        "    def create_mask(self, x): #compute a mask so that the prediction of the next token can only depend on the previous tokens\n",
        "        batch_size, seq_len = x.shape\n",
        "        mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "            batch_size, 1, seq_len, seq_len)\n",
        "        return mask  \n",
        "\n",
        "    def inference(self, x):\n",
        "        #encode and then generate the output token by token greedily\n",
        "        \"\"\"\n",
        "        output_encoder = self.encoder(x)\n",
        "        output = []\n",
        "        for \n",
        "            out = self.decoder(...).argmax(-1)\n",
        "            output.append(out)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, y): \n",
        "        pass\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        #return torch.optim.Adam(self.parameters(), lr=0.02)\n",
        "        pass\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log(\"val_loss\", loss)\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "qiPC8tqNY8wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" example\n",
        "train_loader = DataLoader(MNIST(os.getcwd(), download=True, transform=transforms.ToTensor()))\n",
        "trainer = pl.Trainer(max_epochs=1) #specificare numero di epoche\n",
        "model = Transformer()\n",
        "\n",
        "trainer.fit(model, train_dataloaders=train_loader)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2ISjMj-T2s50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOTA"
      ],
      "metadata": {
        "id": "sEka3B3Eq69g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uf3QJeF-q-AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NON-SOTA"
      ],
      "metadata": {
        "id": "0b4LEKhjtizS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mm-mxAgbtmPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}