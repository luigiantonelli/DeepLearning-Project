{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff9f3af577274fc7a42928a1be9e97bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_837fb69efc23418fa14041d51d8b3f9c",
              "IPY_MODEL_33d1f7612b5b4bcbb70a586d9523d10c",
              "IPY_MODEL_5f2a1c102cdd46848a4289fca8a4bf8e"
            ],
            "layout": "IPY_MODEL_e438020dd3304921a87605f38dfd1661"
          }
        },
        "837fb69efc23418fa14041d51d8b3f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4fc4198e0a478a94559b0513a80151",
            "placeholder": "​",
            "style": "IPY_MODEL_095324f913244f51891b719721799025",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "33d1f7612b5b4bcbb70a586d9523d10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_583b620496f845a0b417ea72546bf740",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6973792d027c464bb47bdcb8bb38c85a",
            "value": 2
          }
        },
        "5f2a1c102cdd46848a4289fca8a4bf8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6762fd17b7614909878cd21f8d70535f",
            "placeholder": "​",
            "style": "IPY_MODEL_0cfc36270cec4c90a31abce1a382b0a5",
            "value": " 2/2 [00:03&lt;00:00,  1.82s/it]"
          }
        },
        "e438020dd3304921a87605f38dfd1661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "3c4fc4198e0a478a94559b0513a80151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095324f913244f51891b719721799025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "583b620496f845a0b417ea72546bf740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6973792d027c464bb47bdcb8bb38c85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6762fd17b7614909878cd21f8d70535f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfc36270cec4c90a31abce1a382b0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "342816fb2da34f219c53a4c505726809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4f3fcafd8de4245a3a6b0e55f88542a",
              "IPY_MODEL_c2c4711233ac4800b7211fbfe3742d3d",
              "IPY_MODEL_360ff4d2c31447da90441aefdb5ca133"
            ],
            "layout": "IPY_MODEL_0e0931ba830046818b4b5bdcb27171ee"
          }
        },
        "e4f3fcafd8de4245a3a6b0e55f88542a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90be5930e0bf4034912af4903ae6422f",
            "placeholder": "​",
            "style": "IPY_MODEL_a4638ee129ff4b9f877b5614f36a5b13",
            "value": "Epoch 0:   2%"
          }
        },
        "c2c4711233ac4800b7211fbfe3742d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969546e8def64f0ab461ce436a24da30",
            "max": 3986,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3503567e95cb42239b8ac0e9238306c0",
            "value": 60
          }
        },
        "360ff4d2c31447da90441aefdb5ca133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43212c81bf4d4487b150b4de3eda1bfa",
            "placeholder": "​",
            "style": "IPY_MODEL_2cca49ca47dd42a98452e67e1aa49be5",
            "value": " 60/3986 [00:07&lt;08:39,  7.56it/s, loss=1.45, v_num=4, train_loss_step=1.390]"
          }
        },
        "0e0931ba830046818b4b5bdcb27171ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "90be5930e0bf4034912af4903ae6422f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4638ee129ff4b9f877b5614f36a5b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "969546e8def64f0ab461ce436a24da30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3503567e95cb42239b8ac0e9238306c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43212c81bf4d4487b150b4de3eda1bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cca49ca47dd42a98452e67e1aa49be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiantonelli/DeepLearning-Project/blob/main/Deep_Learning_Project_Antonelli_Cuconasu_Gaudenzi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "_0HXoR9RpcO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fxGf0hOgnsPD",
        "outputId": "fb2a1c2d-cc1a-4236-8ff5-17f37dae19b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install gdown==4.5.4 --no-cache-dir --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import math\n",
        "import pickle\n",
        "from typing import *\n",
        "from datetime import datetime\n",
        "\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchmetrics\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "\n",
        "# For reproducibility\n",
        "seed_everything(10, workers=True)"
      ],
      "metadata": {
        "id": "DobcczcWqek-",
        "outputId": "986b99c4-5efa-41bf-ef7a-6993142bdee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url = \"https://drive.google.com/drive/folders/1LrGmpT6nVvcWOk-gy656xlFqmH8fIY7k?usp=sharing\"\n",
        "# gdown.download_folder(url=url, quiet=True, use_cookies=False, remaining_ok=True)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNGXDrHt71Y",
        "outputId": "cfba6fff-3126-4ca7-cbfe-3075a432e2e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/DeepLearningProject-Shared\"\n",
        "dataset_folder_path = \"/content/drive/MyDrive/Deep_Learning_Project\"\n",
        "# dataset_folder_path = \"/content/DeepLearning-Shared\"\n",
        "os.chdir(dataset_folder_path)"
      ],
      "metadata": {
        "id": "gDIk7qc1uP4g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89bxAqHuiCnI",
        "outputId": "14b09fb4-1092-459e-8830-6090c67f5df8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets\t\t  modules.txt  prova.txt\n",
            "mathematics_dataset-v1.0  prova2.txt   training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary"
      ],
      "metadata": {
        "id": "PKSCee77ltVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we analyzed all the dataset files to retrieve the characters that will compose the vocabulary. Indeed, we wanted to be sure that our vocabulary contains all the files characters regardless the module we are working on.\n",
        "\n",
        "Moreover, after this pre-processing phase we decided to add the special token `<unk>` (i.e., unknown). Thus, if during inference we are using characters that are not in the vocabulary, we are still able to pre-processes the input, since whathever unknown character is replaced by that special token.  "
      ],
      "metadata": {
        "id": "dN7stnivltVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "    questions = []\n",
        "    answers = []\n",
        "    with open(text_path, 'r') as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            row = line.rstrip().lower() if lowercase else line.rstrip()\n",
        "            # Questions\n",
        "            if idx % 2 == 0:\n",
        "                questions.append(row) \n",
        "            # Answers\n",
        "            else: \n",
        "                answers.append(row)\n",
        "    return questions, answers"
      ],
      "metadata": {
        "id": "BhJnHS2yltVl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(lists_of_texts: List[List[str]]) -> Set[str]:\n",
        "    unified_text = []\n",
        "    \n",
        "    for l in lists_of_texts:\n",
        "        unified_text += l\n",
        "\n",
        "    return Counter(\" \".join(unified_text)).keys()"
      ],
      "metadata": {
        "id": "ttex8hmLltVl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all files\n",
        "folders = ['extrapolate', 'interpolate', 'train-easy', 'train-medium', 'train-hard']\n",
        "files = []\n",
        "\n",
        "for fold in folders:\n",
        "    files += glob.glob(f\"./mathematics_dataset-v1.0/{fold}/*.txt\")"
      ],
      "metadata": {
        "id": "C9VHWlDQltVm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd38269d-3a73-4746-fcb6-f46668838cfd",
        "id": "clPtTD2gltVm"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./mathematics_dataset-v1.0/extrapolate/arithmetic__add_sub_multiple_longer.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/algebra__polynomial_roots_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__add_or_sub_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__div_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__mul_div_multiple_longer.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files_vocabulary(files: List[str], save: bool=False) -> List[str]:\n",
        "    vocabulary = {}\n",
        "    all_lists = []\n",
        "\n",
        "    i = 0\n",
        "    for f in files:\n",
        "        train, test = read_dataset(f)\n",
        "        all_lists += train\n",
        "        all_lists += test\n",
        "        \n",
        "        # Set union\n",
        "        vocabulary |= get_vocabulary(all_lists)\n",
        "        all_lists = []\n",
        "\n",
        "        # Save the vocabulary up to now\n",
        "        if save and i % 10 == 0:\n",
        "            vocabulary = sorted(list(vocabulary))\n",
        "            with open('./datasets/pre_vocabulary.pkl', 'wb') as f:\n",
        "                pickle.dump(vocabulary, f)\n",
        "\n",
        "    # Save sorted vocabulary\n",
        "    vocabulary = sorted(list(vocabulary))\n",
        "    with open('./datasets/pre_vocabulary.pkl', 'wb') as f:\n",
        "        pickle.dump(vocabulary, f)\n",
        "\n",
        "    return vocabulary"
      ],
      "metadata": {
        "id": "-NIjuy8IltVn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This operation requires quite a bit of time (~ 25 min), as we are scanning all the files. So, it is commented to avoid executing it.\n",
        "\n",
        "    vocabulary = get_files_vocabulary(files)"
      ],
      "metadata": {
        "id": "59SVX8yXltVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary_from_set(voc):\n",
        "    vocabulary = {'<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "    i = 4\n",
        "    for v in voc:\n",
        "        vocabulary[v] = i\n",
        "        i += 1\n",
        "    return vocabulary"
      ],
      "metadata": {
        "id": "XnpfxJ_EltVn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./datasets/vocabulary.pkl', 'rb') as f:\n",
        "    vocabulary = pickle.load(f)"
      ],
      "metadata": {
        "id": "IA8mFT9WltVn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bb3c8d-de62-4a78-d94d-a4ce1db59b46",
        "id": "1MoR8XGcltVp"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = create_vocabulary_from_set(vocabulary)"
      ],
      "metadata": {
        "id": "rSZUg9bCltVp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de195ed-4550-42d1-c3d1-3c4b3d8851f8",
        "id": "jUSSoxYsltVp"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<pad>': 0,\n",
              " '<bos>': 1,\n",
              " '<eos>': 2,\n",
              " '<unk>': 3,\n",
              " ' ': 4,\n",
              " '!': 5,\n",
              " \"'\": 6,\n",
              " '(': 7,\n",
              " ')': 8,\n",
              " '*': 9,\n",
              " '+': 10,\n",
              " ',': 11,\n",
              " '-': 12,\n",
              " '.': 13,\n",
              " '/': 14,\n",
              " '0': 15,\n",
              " '1': 16,\n",
              " '2': 17,\n",
              " '3': 18,\n",
              " '4': 19,\n",
              " '5': 20,\n",
              " '6': 21,\n",
              " '7': 22,\n",
              " '8': 23,\n",
              " '9': 24,\n",
              " ':': 25,\n",
              " '<': 26,\n",
              " '=': 27,\n",
              " '>': 28,\n",
              " '?': 29,\n",
              " 'a': 30,\n",
              " 'b': 31,\n",
              " 'c': 32,\n",
              " 'd': 33,\n",
              " 'e': 34,\n",
              " 'f': 35,\n",
              " 'g': 36,\n",
              " 'h': 37,\n",
              " 'i': 38,\n",
              " 'j': 39,\n",
              " 'k': 40,\n",
              " 'l': 41,\n",
              " 'm': 42,\n",
              " 'n': 43,\n",
              " 'o': 44,\n",
              " 'p': 45,\n",
              " 'q': 46,\n",
              " 'r': 47,\n",
              " 's': 48,\n",
              " 't': 49,\n",
              " 'u': 50,\n",
              " 'v': 51,\n",
              " 'w': 52,\n",
              " 'x': 53,\n",
              " 'y': 54,\n",
              " 'z': 55,\n",
              " '{': 56,\n",
              " '}': 57}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "jSp1SqYRiYkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_module_paths(modules: List[str], difficulty: List[str]) -> List[str]:\n",
        "    paths = []\n",
        "\n",
        "    folders = ['train-easy', 'train-medium', 'train-hard']\n",
        "    \n",
        "    if difficulty is not None and set(difficulty).issubset(set(folders)):\n",
        "        folders = difficulty\n",
        "\n",
        "    for module in modules:\n",
        "        for fold in folders:\n",
        "            paths += glob.glob(f\"./mathematics_dataset-v1.0/{fold}/{module}.txt\")\n",
        "\n",
        "    return paths"
      ],
      "metadata": {
        "id": "mM60pprQiaQ-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_files = get_train_module_paths([\"algebra__linear_1d\", \"algebra__linear_2d\"], difficulty=['train-easy'])\n",
        "module_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMYdwf5PibSx",
        "outputId": "7d1af442-4efd-4c69-b09f-c3a939ff23b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt',\n",
              " './mathematics_dataset-v1.0/train-easy/algebra__linear_2d.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_module_paths(modules: List[str]) -> List[str]:\n",
        "    paths = []\n",
        "\n",
        "    for module in modules:\n",
        "        paths += glob.glob(f\"./mathematics_dataset-v1.0/interpolate/{module}.txt\")\n",
        "\n",
        "    return paths"
      ],
      "metadata": {
        "id": "Jxr8UcdfidO6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# algebra_train, algebra_test = read_all_module_files(\"algebra__linear_1d\")"
      ],
      "metadata": {
        "id": "M3RGCojMidzD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(algebra_train)"
      ],
      "metadata": {
        "id": "pgi-i53Piezk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algebra_path = \"./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt\"\n",
        "probability_path = \"./mathematics_dataset-v1.0/train-easy/probability__swr_p_level_set.txt\"\n",
        "prime_path = \"./mathematics_dataset-v1.0/train-easy/numbers__is_prime.txt\""
      ],
      "metadata": {
        "id": "9YnrTBHsigmg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "questions_easy_algebra, answers_easy_algebra = read_dataset(algebra_path)\n",
        "questions_easy_probability, answers_easy_probability = read_dataset(probability_path)\n",
        "questions_easy_prime, answers_easy_prime = read_dataset(prime_path)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EzvNILPFigiI",
        "outputId": "15829d7c-8460-4951-8a2a-cb1d4890c1d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nquestions_easy_algebra, answers_easy_algebra = read_dataset(algebra_path)\\nquestions_easy_probability, answers_easy_probability = read_dataset(probability_path)\\nquestions_easy_prime, answers_easy_prime = read_dataset(prime_path)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no substantial difference in time between loading the entire dataset and pre-processing the data in the __getitem__ method:\n",
        "\n",
        "40 - 60 microsec vs 200 - 300 microsec"
      ],
      "metadata": {
        "id": "WLUVwIiKPqz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d = Mathematics_Dataset(module_files, v)"
      ],
      "metadata": {
        "id": "TK_H6cn3KOED"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# d[8]"
      ],
      "metadata": {
        "id": "0a0xRSGrKQXG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mathematics_Dataset(Dataset):\n",
        "    def __init__(self, modules_paths: List[str], vocabulary: Dict[str, int], max_len_question: int=160, max_len_answer: int=30):\n",
        "        super().__init__()\n",
        "        self.modules_paths = modules_paths\n",
        "        \n",
        "        self.questions = []\n",
        "        self.answers = []\n",
        "        \n",
        "        for m in self.modules_paths:\n",
        "            q_m, a_m = self.read_dataset(m)\n",
        "            self.questions += q_m\n",
        "            self.answers += a_m\n",
        "        \n",
        "        self.max_len_question = max_len_question\n",
        "        self.max_len_answer = max_len_answer\n",
        "        self.vocabulary = vocabulary\n",
        "\n",
        "    def read_dataset(self, text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "        questions = []\n",
        "        answers = []\n",
        "        with open(text_path, 'r') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                row = line.rstrip().lower() if lowercase else line.rstrip()\n",
        "                # Questions\n",
        "                if idx % 2 == 0:\n",
        "                    questions.append(row) \n",
        "                # Answers\n",
        "                else: \n",
        "                    answers.append(row)\n",
        "        return questions, answers\n",
        "\n",
        "    def convert_chars_to_ids(self, sentence: str, max_len: int) -> torch.tensor:\n",
        "        sentence_ids = np.full(max_len + 2, self.vocabulary['<pad>'])\n",
        "\n",
        "        # Start with <bos>\n",
        "        sentence_ids[0] = self.vocabulary['<bos>']\n",
        "\n",
        "        for i, char in enumerate(sentence):\n",
        "            sentence_ids[i + 1] = self.vocabulary.get(char, self.vocabulary['<unk>'])\n",
        "            \n",
        "        # End with <eos>\n",
        "        sentence_ids[len(sentence) + 1] = self.vocabulary['<eos>']\n",
        "\n",
        "        return torch.from_numpy(sentence_ids).long()\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert idx < len(self.questions)\n",
        "        \n",
        "        q, a = self.questions[idx], self.answers[idx]\n",
        "\n",
        "        question = self.convert_chars_to_ids(q, self.max_len_question)\n",
        "        answer = self.convert_chars_to_ids(a, self.max_len_answer)\n",
        "        \n",
        "        return question, answer"
      ],
      "metadata": {
        "id": "WDyOaDodEfWE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d2 = Mathematics_Dataset(module_files, v)"
      ],
      "metadata": {
        "id": "YDOrfk6diob6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# d2[8]"
      ],
      "metadata": {
        "id": "TzEJ-qROOA6e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mathematics_DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, modules: List[str], difficulty: List[str]=None, batch_size: int=32):\n",
        "        super().__init__()\n",
        "        self.modules = modules\n",
        "        self.batch_size = batch_size\n",
        "        self.load_vocabulary()\n",
        "\n",
        "        self.train_modules_paths = get_train_module_paths(self.modules, difficulty)  \n",
        "        self.test_modules_paths = get_test_module_paths(self.modules)        \n",
        "\n",
        "    \n",
        "    def load_vocabulary(self):\n",
        "        with open('./datasets/vocabulary.pkl', 'rb') as f:\n",
        "            v = pickle.load(f)\n",
        "        self.vocabulary = create_vocabulary_from_set(v)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\":\n",
        "            self.math_train = Mathematics_Dataset(self.train_modules_paths, self.vocabulary)\n",
        "            self.math_val = Mathematics_Dataset(self.test_modules_paths, self.vocabulary)\n",
        "\n",
        "        if stage == \"test\":\n",
        "            self.math_test = Mathematics_Dataset(self.test_modules_paths, self.vocabulary)\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.math_train, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    def val_dataloader(self):                                                              \n",
        "        return DataLoader(self.math_val, batch_size=self.batch_size, num_workers=2, pin_memory=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.math_test, batch_size=self.batch_size)\n",
        "\n",
        "    def teardown(self, stage: str):\n",
        "        # Used to clean-up when the run is finished\n",
        "        pass"
      ],
      "metadata": {
        "id": "QVBvNs1QisOI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dm = Mathematics_DataModule(['algebra__linear_1d'], batch_size = 64)"
      ],
      "metadata": {
        "id": "nPg1DDjritNc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "ho9Tk3GctrvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, sqrt_q, mask, dropout_layer = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1)) / sqrt_q\n",
        "    \"\"\"\n",
        "    t [batch_size, self.num_heads, query.size(-2), key.size(-2)]\n",
        "    mask [batch_size, self.num_head, 1 or query.size(-2), key.size(-2)]\n",
        "    \"\"\"\n",
        "    t = t.masked_fill(mask == False, -1e10) #-1e10 acts like -infinity, so that the softmax will consider these tokens less important\n",
        "    t = F.softmax(t, dim = -1)\n",
        "    if dropout_layer is not None:\n",
        "        t = dropout_layer(t)\n",
        "    return torch.matmul(t, value)"
      ],
      "metadata": {
        "id": "9JbWbeOJtt02"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module): \n",
        "    def __init__(self, embedding_dim, num_heads, dropout = 0.2, tp_attention = False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert embedding_dim % num_heads == 0\n",
        "        self.tp_attention = tp_attention\n",
        "        self.dim_head = embedding_dim // num_heads #single head dimension\n",
        "        self.sqrt_q = math.sqrt(self.dim_head)\n",
        "        self.num_heads = num_heads\n",
        "        self.W_q = nn.Linear(embedding_dim, embedding_dim, bias = True) #stack of num_heads matrices of dimension (d, dim_head), one for each head\n",
        "        self.W_k = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_v = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_o = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        if self.tp_attention:\n",
        "            self.W_r = nn.Linear(embedding_dim, embedding_dim, bias = True) #ruolo\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #self.dropout = nn.Dropout(0.15)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.W_q.weight)\n",
        "        nn.init.xavier_uniform_(self.W_k.weight)\n",
        "        nn.init.xavier_uniform_(self.W_v.weight)\n",
        "        nn.init.xavier_uniform_(self.W_o.weight)\n",
        "\n",
        "        if self.tp_attention:\n",
        "            nn.init.normal_(self.W_r.weight, mean=0, std=1./self.sqrt_q)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask): #query, key, value\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        q = self.W_q(query).view(batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        k = self.W_k(key).view(batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        v = self.W_v(value).view(batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "\n",
        "        \"\"\"\n",
        "        in the encoder:\n",
        "            q,k,v ([batch_size, self.num_heads, max_len_question, self.dim_head])\n",
        "            mask (src_mask): [batch_size, 1, 1, max_len_question]\n",
        "\n",
        "        in the decoder (MASKED MULTI-HEAD ATTENTION):\n",
        "            seq_len = current_len_answer if inference else max_len_answer\n",
        "                q,k,v ([batch_size, self.num_head, seq_len, self.dim_head])\n",
        "                mask (trg_mask): [batch_size, 1, seq_len, current_len_answer]\n",
        "                \n",
        "        in the decoder (MULTI-HEAD ATTENTION):\n",
        "            seq_len = current_len_answer if inference else max_len_answer\n",
        "                q ([batch_size, self.num_head, seq_len, self.dim_head])\n",
        "                k,v ([batch_size, self.num_head, max_len_question, self.dim_head])\n",
        "                mask (src_mask): [batch_size, 1, 1, max_len_question]\n",
        "        \"\"\"\n",
        "\n",
        "        attention_value = scaled_dot_product_attention(q, k, v, self.sqrt_q, mask, self.dropout)\n",
        "            #attention_value ([batch_size, self.num_heads, q.size(-2), v.size(-1)])\n",
        "\n",
        "        \n",
        "        if self.tp_attention:\n",
        "            role = self.W_r(query).view(batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "            attention_value *= role  #element-wise product between attention value and role before the final projection\n",
        "        return self.W_o(attention_value.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads*self.dim_head))\n",
        "            #output : ([batch_size, q.size(-2)=query.size(-2),embedding_dim)])"
      ],
      "metadata": {
        "id": "cdtptdthS6Td"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, hidden_size = None, dropout=0.2, tp_attention = False):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = MultiHeadAttention(embedding_dim, num_heads, dropout, tp_attention)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
        "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
        "        \n",
        "        hidden_size = 4*embedding_dim if hidden_size is None else hidden_size\n",
        "        self.ff = nn.Sequential(nn.Linear(embedding_dim, hidden_size, bias = True), \n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(dropout),\n",
        "                                nn.Linear(hidden_size, embedding_dim, bias = True))\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self._init_weights()\n",
        "\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.ff:\n",
        "            if isinstance(p, nn.Linear):\n",
        "                nn.init.xavier_uniform_(p.weight)\n",
        "                if p.bias is not None:\n",
        "                    nn.init.constant_(p.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask): #query, key, value\n",
        "        \"\"\"\n",
        "        if this is a TransformerBlock of the encoder:\n",
        "            query, key, value = x ([batch_size, max_len_question, embedding_dim])\n",
        "\n",
        "        if this is a TransformerBlock of the decoder:\n",
        "            seq_len = current_len_answer if inference else max_len_answer\n",
        "            MASKED MULTI HEAD ATTENTION:\n",
        "                query, key, value = y ([batch_size, seq_len, embedding_dim])\n",
        "            MULTI HEAD ATTENTION:\n",
        "                query: ([batch_size, seq_len, embedding_dim])\n",
        "                key, value: ([batch_size, max_len_question, embedding_dim])\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        x = query + self.dropout1(self.attention(query, key, value, mask)) #query as res conn because the decoder block requires it and it doesn't matter for encoder blocks\n",
        "        x = self.norm1(x)\n",
        "        x = x + self.dropout2(self.ff(x))\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhrmQH8sUHwE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, hidden_size, dropout = 0.2, tp_attention = False):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.masked_attention = MultiHeadAttention(embedding_dim, num_heads, dropout, tp_attention)\n",
        "        self.norm = nn.LayerNorm(embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.transformer_block = TransformerBlock(embedding_dim, num_heads, hidden_size, dropout, tp_attention)\n",
        "\n",
        "    def forward(self, output_encoder, src_mask, y, trg_mask):\n",
        "        y = y + self.dropout(self.masked_attention(y, y, y, trg_mask)) #masked attention (y = query = key = value) + residual connection\n",
        "        y = self.norm(y)\n",
        "        return self.transformer_block(y, output_encoder, output_encoder, src_mask)#query from the masked mha and key and value from the encoder"
      ],
      "metadata": {
        "id": "w0MIvv-ZWL-M"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_len=256):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, embedding_dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * -(math.log(10000.0) / embedding_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x + Variable(self.pe[:, :x.size(1)], requires_grad = False)"
      ],
      "metadata": {
        "id": "qrsDFyoyUF0D"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, hidden_size, dropout, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.encoder = nn.ModuleList(\n",
        "            [TransformerBlock(embedding_dim, num_heads, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, x, mask): \n",
        "        # x ([batch_size, max_len_question, embedding_dim])\n",
        "        for block in self.encoder:\n",
        "            x = block(x, x, x, mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bgNDRuG5YIWz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, hidden_size, dropout = 0.2, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.decoder = nn.ModuleList(\n",
        "            [DecoderBlock(embedding_dim, num_heads, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, output_encoder, src_mask, y, trg_mask): \n",
        "        for block in self.decoder:\n",
        "            y = block(output_encoder, src_mask, y, trg_mask)\n",
        "        return y"
      ],
      "metadata": {
        "id": "Aybtz4uUY8vQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self, \n",
        "        special_idxs: Dict[str, int], \n",
        "        optimizer_params: dict,\n",
        "        learning_rate: float=1e-4,\n",
        "        num_heads: int=4, \n",
        "        embedding_dim: int=256, \n",
        "        hidden_size: int=512, \n",
        "        vocabulary_size: int=58,\n",
        "        max_len_question: int=162,\n",
        "        max_len_answer: int=32,\n",
        "        num_blocks_encoder: int=6, \n",
        "        num_blocks_decoder: int=6, \n",
        "        dropout: float=0.2, \n",
        "        gradient_clip_val: float=0.9,\n",
        "        tp_attention: bool=False\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.bos_id = special_idxs['<bos>']\n",
        "        self.eos_id = special_idxs['<eos>']\n",
        "        self.pad_id = special_idxs['<pad>']\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_heads = num_heads\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "        \n",
        "        self.token_embedding = nn.Embedding(vocabulary_size, embedding_dim, padding_idx=self.pad_id)\n",
        "        self.positional_embedding = PositionalEncoding(embedding_dim)\n",
        "        self.encoder = TransformerEncoder(embedding_dim, num_heads, hidden_size, dropout, num_blocks_encoder, tp_attention)\n",
        "        self.decoder = TransformerDecoder(embedding_dim, num_heads, hidden_size, dropout, num_blocks_decoder, tp_attention)\n",
        "        self.to_logits = nn.Linear(embedding_dim, vocabulary_size)\n",
        "        \n",
        "        self.max_len_question = max_len_question\n",
        "        self.max_len_answer = max_len_answer\n",
        "\n",
        "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.train_accuracy2 = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.train_accuracy3 = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.test_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.token_embedding.weight, \n",
        "                        mean=0, std=1./math.sqrt(self.embedding_dim))\n",
        "        \n",
        "        nn.init.normal_(self.to_logits.weight, \n",
        "                        mean=0, std=1./math.sqrt(self.vocabulary_size))\n",
        "\n",
        "        if self.to_logits.bias is not None:\n",
        "            nn.init.constant_(self.to_logits.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "    def create_trg_mask(self, y): #compute a mask so that the prediction of the next token can only depend on the previous tokens\n",
        "        # #[batch_size, 1, len, len] & [batch_size, 1, 1, len]\n",
        "        return self.create_causal_mask(y) & self.create_padding_mask(y)\n",
        "\n",
        "\n",
        "    def create_causal_mask(self, y):\n",
        "        batch_size, seq_len = y.shape\n",
        "        mask = torch.tril(torch.ones((seq_len, seq_len), dtype=torch.bool, device = self.device)).expand(\n",
        "            batch_size, 1, seq_len, seq_len)\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def create_padding_mask(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        mask = (x != self.pad_id).unsqueeze(-2).unsqueeze(-2)\n",
        "        return mask\n",
        "\n",
        "    def greedy_decode(self,x):\n",
        "        batch_size = x.size(0)\n",
        "        src_mask = self.create_padding_mask(x)\n",
        "        # src_mask ([batch_size, 1, 1, self.max_len_question]), \n",
        "                #la dimensione [-2] è 1 perché per ogni token della domanda la maschera è la stessa (broadcasting)\n",
        "        x = self.token_embedding(x)\n",
        "        x = self.positional_embedding(x)\n",
        "        #x ([batch_size, self.max_len_question, self.embedding_dim])\n",
        "\n",
        "        output_encoder = self.encoder(x, src_mask)\n",
        "        #output_encoder : ([batch_size, self.max_len_question, embedding_dim]) \n",
        "\n",
        "        output = torch.ones(batch_size, 1, dtype=torch.int64, device = self.device).fill_(self.bos_id)\n",
        "        #output: ([batch_size, 1]) \n",
        "        done = torch.zeros(batch_size, dtype = torch.uint8, device = self.device)\n",
        "        for _ in range(self.max_len_answer - 1): \n",
        "            trg_mask = self.create_trg_mask(output)\n",
        "            # tgr_mask ([batch_size, 1, len_current_answer, len_current_answer])\n",
        "\n",
        "            output_embedding = self.token_embedding(output)\n",
        "            output_embedding = self.positional_embedding(output_embedding)\n",
        "            #output_embedding ([batch_size, len_current_answer, self.embedding_dim])\n",
        "\n",
        "            out = self.decoder(output_encoder, src_mask, output_embedding, trg_mask)\n",
        "            #out ([batch_size, len_current_answer, self.embedding_dim])\n",
        "            out = self.to_logits(out)\n",
        "            #out ([batch_size, len_current_answer, self.vocabulary_size])\n",
        "            out = torch.argmax(out[:,[-1],:], dim = -1)\n",
        "            output = torch.cat([output, out], dim = 1) #we concatenate the new token to the output answer\n",
        "            eos_reached = out.squeeze(1) == self.eos_id\n",
        "            done |= eos_reached\n",
        "            if done.sum() == batch_size:\n",
        "                break\n",
        "        return output\n",
        "\n",
        "\n",
        "    def inference(self, x):\n",
        "        #encode and then generate the output token by token greedily\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            return self.greedy_decode(x)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \n",
        "        # x ([batch_size, self.max_len_question])\n",
        "        # y ([batch_size, self.max_len_answer])\n",
        "\n",
        "        src_mask = self.create_padding_mask(x)\n",
        "\n",
        "        # src_mask ([batch_size, 1, 1, self.max_len_question]),\n",
        "                    #la dimensione [-3] è 1 perché successivamente viene effettuato broadcasting per ogni head della MULTI-HEAD ATTENTION \n",
        "                    #la dimensione [-2] è 1 perché per ogni token della domanda la maschera è la stessa (broadcasting)\n",
        "\n",
        "        trg_mask = self.create_trg_mask(y)\n",
        "\n",
        "        # tgr_mask ([batch_size, 1, self.max_len_answer-1, self.max_len_answer-1]),\n",
        "                    #la dimensione [-3] è 1 perché successivamente viene effettuato broadcasting per ogni head della MULTI-HEAD ATTENTION \n",
        "                    #la dimensione [-2] è self.max_len_answer perché per ogni token della domanda la maschera è diversa (maschera causale)\n",
        "\n",
        "\n",
        "        x = self.token_embedding(x)\n",
        "\n",
        "        x = self.positional_embedding(x)\n",
        "\n",
        "        #x ([batch_size, self.max_len_question, self.embedding_dim])\n",
        "\n",
        "        y = self.token_embedding(y)\n",
        "        y = self.positional_embedding(y)\n",
        "\n",
        "        #y ([batch_size, self.max_len_answer-1, self.embedding_dim])\n",
        "\n",
        "        output_encoder = self.encoder(x, src_mask)\n",
        "\n",
        "        #output_encoder : ([batch_size, self.max_len_question, embedding_dim])        \n",
        "\n",
        "        output_decoder = self.decoder(output_encoder, src_mask, y, trg_mask)\n",
        "\n",
        "        #output_decoder : ([batch_size, self.max_len_answer-1, embedding_dim]))\n",
        "\n",
        "        return self.to_logits(output_decoder).transpose(1,2)\n",
        "    \n",
        "    def configure_optimizers(self):# learning rate = 1x10^-4; beta1 =0.9; beta2 = 0.995 dal paper\n",
        "        betas = self.optimizer_params['betas']\n",
        "        return torch.optim.Adam(self.parameters(), self.learning_rate, betas)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x, y[:, :-1])\n",
        "        loss = F.cross_entropy(y_pred, y[:, 1:], ignore_index = self.pad_id)\n",
        "        \n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        self.train_accuracy.update(y_pred, y[:, 1:])\n",
        "        self.log('train_accuracy_forward', self.train_accuracy.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        y_pred2 = self.greedy_decode(x)  #[batch_size, max_eos_found]\n",
        "        y_pred2 = F.pad(y_pred2, (0, self.max_len_answer - y_pred2.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.train_accuracy2.update(y_pred2[:, 1:], y[:, 1:])\n",
        "        self.log('train_accuracy_greedydecode', self.train_accuracy2.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        y_pred3 = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred3 = F.pad(y_pred3, (0, self.max_len_answer - y_pred3.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.train_accuracy3.update(y_pred3[:, 1:], y[:, 1:])\n",
        "        self.log('train_accuracy_inference', self.train_accuracy3.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        return loss, self.train_accuracy.compute(), self.compute_accuracy(p.transpose(1,2),y,0)\n",
        "\n",
        "    def compute_accuracy(self, logits, targets, pad_value):\n",
        "        \"\"\"\n",
        "        Compute full sequence accuracy of a batch.\n",
        "        :param logits: the model logits (batch_size, seq_len, out_dim)\n",
        "        :param targets: the true targets (batch_size, seq_len)\n",
        "        :param pad_value: PAD value used to fill end of target seqs\n",
        "        :return: continous accuracy between 0.0 and 1.0\n",
        "        \"\"\"\n",
        "        trg_shifted = targets[:, 1:]              # drop the SOS from targets\n",
        "        y_hat = torch.argmax(logits, dim=-1)      # get index predictions from logits\n",
        "\n",
        "        # count matches in batch, masking out pad values in each target\n",
        "        matches = (torch.eq(trg_shifted,y_hat) | (trg_shifted==pad_value)).all(1).sum().item()\n",
        "        \n",
        "        acc_percent = matches / len(logits)\n",
        "        return acc_percent\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.val_accuracy.update(y_pred[:, 1:], y[:, 1:]) #y_pred, y nel caso volessimo contare <bos> come carattere corretto\n",
        "        self.log('val_accuracy_step', self.val_accuracy.compute(), on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.test_accuracy.update(y_pred[:, 1:], y[:, 1:])\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('val_accuracy_epoch', self.val_accuracy.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.val_accuracy.reset()\n",
        "        \n",
        "        # Also reset the training accuracy\n",
        "        self.train_accuracy.reset()\n",
        "        self.train_accuracy2.reset()\n",
        "        self.train_accuracy3.reset()\n",
        "\n",
        "    \n",
        "    def test_epoch_end(self, outputs):\n",
        "        self.log('test_accuracy_epoch', self.test_accuracy.compute(), on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.test_accuracy.reset()\n"
      ],
      "metadata": {
        "id": "qiPC8tqNY8wN"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocabulary = v\n",
        "LEARNING_RATE = 1e-4 # 2.558585886905645e-05\n",
        "BATCH_SIZE = 128\n",
        "EMBEDDING_DIM = 16\n",
        "NUM_HEADS = 4\n",
        "assert EMBEDDING_DIM % NUM_HEADS == 0\n",
        "# HIDDEN_SIZE = 2048\n",
        "HIDDEN_SIZE = 16\n",
        "DROP_PROB = 0.5\n",
        "GRADIENT_CLIP_VAL = 0.5\n",
        "NUM_BLOCKS_ENCODER = 1\n",
        "NUM_BLOCKS_DECODER = 1\n",
        "SPECIAL_CHAR_DICT = {'<bos>': vocabulary['<bos>'], '<eos>': vocabulary['<eos>'], '<pad>': vocabulary['<pad>']}\n",
        "OPTIMIZER_PARAMS = {'betas': (0.9, 0.995)}\n",
        "\n",
        "tp_transformer_hyperparams = {\n",
        "    \"special_idxs\": SPECIAL_CHAR_DICT,\n",
        "    \"optimizer_params\": OPTIMIZER_PARAMS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"num_heads\": NUM_HEADS,\n",
        "    \"embedding_dim\": EMBEDDING_DIM,\n",
        "    \"hidden_size\": HIDDEN_SIZE,\n",
        "    \"vocabulary_size\": len(vocabulary),\n",
        "    \"num_blocks_encoder\": NUM_BLOCKS_ENCODER,\n",
        "    \"num_blocks_decoder\": NUM_BLOCKS_DECODER,\n",
        "    \"dropout\": DROP_PROB,\n",
        "    \"gradient_clip_val\": GRADIENT_CLIP_VAL, # Added just to be saved\n",
        "    \"tp_attention\": True\n",
        "}\n",
        "\n",
        "tp_transformer = Transformer(**tp_transformer_hyperparams)\n",
        "modules = ['algebra__linear_1d']\n",
        "math_dm = Mathematics_DataModule(modules, batch_size=4)\n"
      ],
      "metadata": {
        "id": "lSsMh3G73IZW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" #possibile alternativa a greedy_decode\n",
        "def beam_search(self, x, k = 3):\n",
        "    batch_size = x.size(0)\n",
        "    src_mask = self.create_padding_mask(x)\n",
        "    # src_mask [batch_size, 1, 1, self.max_len_question] \n",
        "         \n",
        "    x = self.token_embedding(x)\n",
        "    x = self.positional_embedding(x)\n",
        "    #x [batch_size, self.max_len_question, self.embedding_dim]\n",
        "\n",
        "    output_encoder = self.encoder(x, src_mask)\n",
        "    #output_encoder [batch_size, self.max_len_question, embedding_dim]\n",
        "\n",
        "    # Create initial input for the decoder\n",
        "    start = torch.ones(batch_size, 1, dtype=torch.int64, device=self.device).fill_(self.bos_id)\n",
        "\n",
        "    sequences = [(start, 0)] * batch_size\n",
        "\n",
        "    for _ in range(self.max_len_answer - 1): \n",
        "        candidates = [] # List of candidate sequences for each example in the batch\n",
        "\n",
        "        for sequence, score in sequences:\n",
        "            # If sequence is already ended, add it to the candidate list and continue with the next sequence\n",
        "            if sequence.squeeze(1)[-1] == self.eos_id:\n",
        "                candidates.append((sequence, score))\n",
        "                continue\n",
        "\n",
        "            trg_mask = self.create_trg_mask(sequence)\n",
        "            # tgr_mask [batch_size, 1, len_current_answer, len_current_answer]\n",
        "\n",
        "            output_embedding = self.token_embedding(sequence)\n",
        "            output_embedding = self.positional_embedding(output_embedding)\n",
        "            #output_embedding [batch_size, len_current_answer, self.embedding_dim]\n",
        "\n",
        "            out = self.decoder(output_encoder, src_mask, output_embedding, trg_mask)\n",
        "            #out [batch_size, len_current_answer, self.embedding_dim]\n",
        "            out = self.to_logits(out)\n",
        "            #out [batch_size, len_current_answer, self.vocabulary_size]\n",
        "\n",
        "            # Get top-k most likely next tokens and their scores\n",
        "            scores, indices = torch.topk(out[:, -1, :], k=k)\n",
        "            for i in range(beam_size):\n",
        "                token = indices[:, i].unsqueeze(1)\n",
        "                prob = scores[:, i].unsqueeze(1)\n",
        "                new_sequence = torch.cat([sequence, token], dim=1)\n",
        "                new_score = score - torch.log(prob) # use log-probability to prevent underflow\n",
        "                candidates.append((new_sequence, new_score))\n",
        "\n",
        "        # Select the k best sequences for each example in the batch\n",
        "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
        "        sequences = candidates[:k*batch_size]\n",
        "\n",
        "    # Select the best sequence for each example in the batch\n",
        "    outputs = []\n",
        "    for sequence, score in sequences:\n",
        "        outputs.append(sequence)\n",
        "    outputs = torch.stack(outputs, dim=0)\n",
        "    return outputs\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gniADSaBNMdY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "15ae946f-1dc4-4981-a280-a5fbfac5d696"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' #possibile alternativa a greedy_decode\\ndef beam_search(self, x, k = 3):\\n    batch_size = x.size(0)\\n    src_mask = self.create_padding_mask(x)\\n    # src_mask [batch_size, 1, 1, self.max_len_question] \\n         \\n    x = self.token_embedding(x)\\n    x = self.positional_embedding(x)\\n    #x [batch_size, self.max_len_question, self.embedding_dim]\\n\\n    output_encoder = self.encoder(x, src_mask)\\n    #output_encoder [batch_size, self.max_len_question, embedding_dim]\\n\\n    # Create initial input for the decoder\\n    start = torch.ones(batch_size, 1, dtype=torch.int64, device=self.device).fill_(self.bos_id)\\n\\n    sequences = [(start, 0)] * batch_size\\n\\n    for _ in range(self.max_len_answer - 1): \\n        candidates = [] # List of candidate sequences for each example in the batch\\n\\n        for sequence, score in sequences:\\n            # If sequence is already ended, add it to the candidate list and continue with the next sequence\\n            if sequence.squeeze(1)[-1] == self.eos_id:\\n                candidates.append((sequence, score))\\n                continue\\n\\n            trg_mask = self.create_trg_mask(sequence)\\n            # tgr_mask [batch_size, 1, len_current_answer, len_current_answer]\\n\\n            output_embedding = self.token_embedding(sequence)\\n            output_embedding = self.positional_embedding(output_embedding)\\n            #output_embedding [batch_size, len_current_answer, self.embedding_dim]\\n\\n            out = self.decoder(output_encoder, src_mask, output_embedding, trg_mask)\\n            #out [batch_size, len_current_answer, self.embedding_dim]\\n            out = self.to_logits(out)\\n            #out [batch_size, len_current_answer, self.vocabulary_size]\\n\\n            # Get top-k most likely next tokens and their scores\\n            scores, indices = torch.topk(out[:, -1, :], k=k)\\n            for i in range(beam_size):\\n                token = indices[:, i].unsqueeze(1)\\n                prob = scores[:, i].unsqueeze(1)\\n                new_sequence = torch.cat([sequence, token], dim=1)\\n                new_score = score - torch.log(prob) # use log-probability to prevent underflow\\n                candidates.append((new_sequence, new_score))\\n\\n        # Select the k best sequences for each example in the batch\\n        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\\n        sequences = candidates[:k*batch_size]\\n\\n    # Select the best sequence for each example in the batch\\n    outputs = []\\n    for sequence, score in sequences:\\n        outputs.append(sequence)\\n    outputs = torch.stack(outputs, dim=0)\\n    return outputs\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA_6r6wjx5sF",
        "outputId": "db07fa7e-5871-44d1-d754-4d44dcfd7190"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor(0.0833), 0.0),\n",
              " (tensor(0.0870), 0.0),\n",
              " (tensor(0.0909), 0.0),\n",
              " (tensor(0.0714), 0.0),\n",
              " (tensor(0.0962), 0.0),\n",
              " (tensor(0.0833), 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOTA"
      ],
      "metadata": {
        "id": "sEka3B3Eq69g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = v"
      ],
      "metadata": {
        "id": "n-5i8lY1sEIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Luigi\"\n",
        "\n",
        "root_dir = \"./training/checkpoints\"\n",
        "logger_dir = \"./training/tensorboard/logs\"\n",
        "checkpoint_dir = \"./training/checkpoints/PRO_\" + name + \"_tp_transformer_checkpoints\"\n",
        "#checkpoint_dir = \"./training/checkpoints/Standard_Luigi_tp_transformer_checkpoints\"\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 1e-4 # 2.558585886905645e-05\n",
        "BATCH_SIZE = 128\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_SIZE = 64\n",
        "NUM_HEADS = 4\n",
        "assert EMBEDDING_DIM % NUM_HEADS == 0\n",
        "\n",
        "DROP_PROB = 0.5\n",
        "GRADIENT_CLIP_VAL = 0.5\n",
        "NUM_BLOCKS_ENCODER = 3\n",
        "NUM_BLOCKS_DECODER = 3\n",
        "SPECIAL_CHAR_DICT = {'<bos>': vocabulary['<bos>'], '<eos>': vocabulary['<eos>'], '<pad>': vocabulary['<pad>']}\n",
        "OPTIMIZER_PARAMS = {'betas': (0.9, 0.995)}"
      ],
      "metadata": {
        "id": "0aPW_6wrs_IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp_transformer_hyperparams = {\n",
        "    \"special_idxs\": SPECIAL_CHAR_DICT,\n",
        "    \"optimizer_params\": OPTIMIZER_PARAMS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"num_heads\": NUM_HEADS,\n",
        "    \"embedding_dim\": EMBEDDING_DIM,\n",
        "    \"hidden_size\": HIDDEN_SIZE,\n",
        "    \"vocabulary_size\": len(vocabulary),\n",
        "    \"num_blocks_encoder\": NUM_BLOCKS_ENCODER,\n",
        "    \"num_blocks_decoder\": NUM_BLOCKS_DECODER,\n",
        "    \"dropout\": DROP_PROB,\n",
        "    \"gradient_clip_val\": GRADIENT_CLIP_VAL, # Added just to be saved\n",
        "    \"tp_attention\": True\n",
        "}\n",
        "\n",
        "#now = datetime.now().strftime(\"%H.%M\")\n",
        "\n",
        "logger = TensorBoardLogger(logger_dir, name=\"PRO_tp_transformer\")\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir,\n",
        "    filename='tp_transformer_{epoch:02d}_{step:06d}_{val_accuracy_epoch:.3f}',\n",
        "    save_top_k=6,\n",
        "    monitor='val_accuracy_epoch',\n",
        "    mode='max',\n",
        "    verbose=True,\n",
        "    save_last=True\n",
        ")\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "trainer_hyperparams = {\n",
        "    \"default_root_dir\": root_dir,\n",
        "    \"accelerator\": \"auto\",\n",
        "    \"devices\": 1,\n",
        "    \"precision\": 32, #16 if torch.cuda.is_available() else 32, # ADDED\n",
        "    \"log_every_n_steps\": 100,\n",
        "    # \"val_check_interval\": 0.5, # validation step called 2 times during a training epoch\n",
        "    \"val_check_interval\": 1.0, \n",
        "    \"gradient_clip_val\": GRADIENT_CLIP_VAL,\n",
        "    \"max_epochs\": EPOCHS,\n",
        "    \"logger\": logger,\n",
        "    \"callbacks\": callbacks,\n",
        "    # \"deterministic\": True,\n",
        "}\n",
        "\n",
        "#modules = ['algebra__linear_1d', 'probability__swr_p_level_set', 'numbers__is_prime']\n",
        "modules = ['algebra__linear_1d']\n",
        "math_dm = Mathematics_DataModule(modules, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "mWWvh1A5m5-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp_transformer = Transformer(**tp_transformer_hyperparams)\n",
        "trainer = Trainer(**trainer_hyperparams)\n",
        "\n",
        "#trainer.fit(tp_transformer, datamodule=math_dm)\n",
        "math_dm.setup(\"fit\")\n",
        "trainer.fit(tp_transformer, train_dataloaders=math_dm.train_dataloader(), val_dataloaders=math_dm.val_dataloader())"
      ],
      "metadata": {
        "id": "Uf3QJeF-q-AW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "ff9f3af577274fc7a42928a1be9e97bf",
            "837fb69efc23418fa14041d51d8b3f9c",
            "33d1f7612b5b4bcbb70a586d9523d10c",
            "5f2a1c102cdd46848a4289fca8a4bf8e",
            "e438020dd3304921a87605f38dfd1661",
            "3c4fc4198e0a478a94559b0513a80151",
            "095324f913244f51891b719721799025",
            "583b620496f845a0b417ea72546bf740",
            "6973792d027c464bb47bdcb8bb38c85a",
            "6762fd17b7614909878cd21f8d70535f",
            "0cfc36270cec4c90a31abce1a382b0a5",
            "342816fb2da34f219c53a4c505726809",
            "e4f3fcafd8de4245a3a6b0e55f88542a",
            "c2c4711233ac4800b7211fbfe3742d3d",
            "360ff4d2c31447da90441aefdb5ca133",
            "0e0931ba830046818b4b5bdcb27171ee",
            "90be5930e0bf4034912af4903ae6422f",
            "a4638ee129ff4b9f877b5614f36a5b13",
            "969546e8def64f0ab461ce436a24da30",
            "3503567e95cb42239b8ac0e9238306c0",
            "43212c81bf4d4487b150b4de3eda1bfa",
            "2cca49ca47dd42a98452e67e1aa49be5"
          ]
        },
        "outputId": "cd306c64-0207-4711-f193-55624970fc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /content/drive/.shortcut-targets-by-id/1IS7xxoH06-zPLbTk07CAGSmtMTFE85h_/Deep_Learning_Project/training/checkpoints/Standard_Luigi_tp_transformer_checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                 | Type               | Params\n",
            "------------------------------------------------------------\n",
            "0 | token_embedding      | Embedding          | 3.7 K \n",
            "1 | positional_embedding | PositionalEncoding | 0     \n",
            "2 | encoder              | TransformerEncoder | 88.1 K\n",
            "3 | decoder              | TransformerDecoder | 150 K \n",
            "4 | to_logits            | Linear             | 3.8 K \n",
            "5 | train_accuracy       | MulticlassAccuracy | 0     \n",
            "6 | train_accuracy2      | MulticlassAccuracy | 0     \n",
            "7 | train_accuracy3      | MulticlassAccuracy | 0     \n",
            "8 | val_accuracy         | MulticlassAccuracy | 0     \n",
            "9 | test_accuracy        | MulticlassAccuracy | 0     \n",
            "------------------------------------------------------------\n",
            "246 K     Trainable params\n",
            "0         Non-trainable params\n",
            "246 K     Total params\n",
            "0.986     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff9f3af577274fc7a42928a1be9e97bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "342816fb2da34f219c53a4c505726809"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2898vCqeaAsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_hyperparams = torch.load(f\"{checkpoint_dir}/last-v3.ckpt\")\n",
        "trained_hyperparams['hyper_parameters']"
      ],
      "metadata": {
        "id": "vzfHUGm_xyH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = Transformer(**tp_transformer_hyperparams)\n",
        "test_trainer = Trainer(**trainer_hyperparams)\n",
        "\"\"\"\n",
        "# test_trainer.test(test_model, datamodule=math_dm, ckpt_path=f\"{checkpoint_dir}/tp_transformer_epoch=00_step=001464_val_accuracy_epoch=0.287.ckpt\", verbose=True)\n",
        "test_trainer.test(test_model, datamodule=math_dm, ckpt_path=\"best\", verbose=True) # ckpt_path=\"best\"\n",
        "\"\"\"\n",
        "math_dm.setup(\"test\")\n",
        "test_trainer.test(test_model, dataloaders = math_dm.test_dataloader(), ckpt_path=\"best\", verbose=True)"
      ],
      "metadata": {
        "id": "IZZflQpInBdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./training/tensorboard/logs/TP-Transformer #modifica in base al tuo path"
      ],
      "metadata": {
        "id": "-TeR1elp0lzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"./training/checkpoints/tp_transformer_checkpoints\"  \n",
        "logger = TensorBoardLogger(logger_dir, name=\"TP-Transformer\", log_graph=True)\n",
        "\n",
        "\n",
        "\n",
        "ckpt_path = checkpoint_dir + \"/last.ckpt\"  #attenzione che in caso di nuovi last checkpoint il nome è diverso\n",
        "checkpoint_dir_fineTuning = \"./training/checkpoints/tp_transformer_checkpoints_fineTuning\"\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir_fineTuning,\n",
        "    filename='tp_transformer_{epoch:02d}_{step:06d}',\n",
        "    save_top_k=3,\n",
        "    monitor='accuracy_epoch',\n",
        "    mode='max',\n",
        "    save_last=True\n",
        ")\n",
        "tp_transformer_ckpt = Transformer.load_from_checkpoint(ckpt_path)\n",
        "\n",
        "\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "trainer = pl.Trainer(log_every_n_steps=1, default_root_dir=root_dir, accelerator='auto', devices=1, gradient_clip_val = 0.1, max_epochs = EPOCHS + ADDITIONAL_EPOCHS, logger = logger, callbacks = callbacks)\n",
        "math_dm = Mathematics_DataModule(['algebra__linear_1d'], batch_size = BATCH_SIZE)\n",
        "trainer.fit(tp_transformer_ckpt, datamodule = math_dm, ckpt_path = ckpt_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "tPoVmsfdFUcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NON-SOTA (Transformer)"
      ],
      "metadata": {
        "id": "0b4LEKhjtizS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = v"
      ],
      "metadata": {
        "id": "RnAfZahj3PuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"./training/checkpoints\"\n",
        "logger_dir = \"./training/tensorboard/logs\"\n",
        "checkpoint_dir = \"./training/checkpoints/transformer_vanilla_checkpoints.ckpt\"\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 4\n",
        "EMBEDDING_DIM = 256\n",
        "NUM_HEADS = 8\n",
        "assert EMBEDDING_DIM % NUM_HEADS == 0\n",
        "HIDDEN_SIZE = 512\n",
        "DROP_PROB = 0.2\n",
        "NUM_BLOCKS_ENCODER = 6\n",
        "NUM_BLOCKS_DECODER = 6\n",
        "SPECIAL_CHAR_DICT = {'<bos>': vocabulary['<bos>'], '<eos>': vocabulary['<eos>'], '<pad>': vocabulary['<pad>']}\n",
        "\n",
        "\n",
        "ADDITIONAL_EPOCHS = 5"
      ],
      "metadata": {
        "id": "cmfS_iAe357E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_vanilla = Transformer(\n",
        "    SPECIAL_CHAR_DICT, embedding_dim = EMBEDDING_DIM, num_heads = NUM_HEADS, hidden_size = HIDDEN_SIZE, \n",
        "    dropout = DROP_PROB, vocabulary_size = len(vocabulary), num_blocks_encoder = NUM_BLOCKS_ENCODER,\n",
        "    num_blocks_decoder = NUM_BLOCKS_DECODER\n",
        "    )\n",
        "\n",
        "logger = TensorBoardLogger(logger_dir, name=\"Transformer-Vanilla\", log_graph=True)\n",
        "\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir,\n",
        "    filename='transformer_vanilla_{epoch:02d}_{step:06d}',\n",
        "    save_top_k=3,\n",
        "    monitor='accuracy_epoch',\n",
        "    mode='max',\n",
        "    save_last=True\n",
        ")\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(default_root_dir=root_dir, accelerator='auto', devices=1, gradient_clip_val = 0.1, max_epochs = EPOCHS+ADDITIONAL_EPOCHS, logger = logger, callbacks = callbacks)\n",
        "math_dm = Mathematics_DataModule(['algebra__linear_1d'], batch_size = BATCH_SIZE)\n",
        "trainer.fit(transformer_vanilla, datamodule = math_dm)\n"
      ],
      "metadata": {
        "id": "FtATASTk4PIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.validate(datamodule=dm)\n",
        "trainer.test(datamodule=dm)"
      ],
      "metadata": {
        "id": "XhMRvMTl4ujG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./training/tensorboard/logs/Transformer-Vanilla"
      ],
      "metadata": {
        "id": "PMLeHmow4vNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "da fare:\n",
        "\n",
        "-  controllare l'architettura GRU (FATTO)\n",
        "\n",
        "-  controllare teacher forcing (FATTO)\n",
        "\n",
        "\n",
        "\n",
        "-  utilizzare stage (parametro di setup) per caricare anche un solo dataset se stage = \"train\" ad esempio \n",
        "   (https://colab.research.google.com/drive/1oJrA-Q-neOl1fCQJhIWR_GmxpYaG-cFx?authuser=1#scrollTo=JM57yq7bJS0E)\n",
        "\n",
        "-  aggiungere predict_step nel pl.LightningModule dove si chiama inference e relativo predict dataloader nel Lightning data module\n",
        "\n",
        "\n",
        "-  RNN fatte molto bene:\n",
        "    https://github.com/georgeyiasemis/Recurrent-Neural-Networks-from-scratch-using-PyTorch \n",
        "    https://towardsdatascience.com/building-a-lstm-by-hand-on-pytorch-59c02a4ec091\n",
        "    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n"
      ],
      "metadata": {
        "id": "ApqMCU6H92SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = v"
      ],
      "metadata": {
        "id": "mwaoQg_uL7RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wx = nn.Linear(input_size, 3*hidden_size, bias=True)\n",
        "        self.Wh_gate = nn.Linear(hidden_size, 2*hidden_size, bias=True)\n",
        "\n",
        "        self.Whh = nn.Linear(hidden_size, hidden_size, bias = True)\n",
        "        \n",
        "        #nell'implementazione del git c'è anche una funzione reset_parameters\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        x_reset, x_update, x_candidate = torch.tensor_split(self.Wx(x), 3, dim=-1)\n",
        "        \"\"\"\n",
        "        print(f\"shape h {h.shape}\")\n",
        "        print(f\"shape {x.shape}\")\n",
        "        print(f\"hidden_size {self.hidden_size}\")\n",
        "        print(f\"input_size {self.input_size}\")\n",
        "        \"\"\"\n",
        "        h_reset, h_update = torch.tensor_split(self.Wh_gate(h), 2, dim=-1)\n",
        "\n",
        "        reset_gate = torch.sigmoid(x_reset + h_reset)\n",
        "\n",
        "        update_gate = torch.sigmoid(x_update + h_update)\n",
        "\n",
        "        h_candidate = torch.tanh(x_candidate + self.Whh(reset_gate * h))   \n",
        "\n",
        "        h_t = update_gate * h + (1-update_gate) * h_candidate\n",
        "\n",
        "        return h_t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SQZWw42ef55J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    \n",
        "    def __init__ (self, input_size, hidden_size, num_cells=2):\n",
        "        assert num_cells>0\n",
        "\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.num_cells = num_cells\n",
        "        \n",
        "        self.GRU_cells = nn.ModuleList(\n",
        "            [GRUCell(input_size, hidden_size)]+[GRUCell(hidden_size, hidden_size) for _ in range(1, num_cells)])\n",
        "        \n",
        "    def forward(self, x, h=None):\n",
        "        \"x è una sequenza [batch, seq_len, embedding_dim]\"\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        \"h [self.num_cells, batch_size, self.hidden_size]\"\n",
        "        #output_states = torch.stack([torch.zeros(batch_size, self.hidden_size) for _ in range(seq_len)], dim = 0)\n",
        "        output_states = torch.zeros(batch_size, seq_len, self.hidden_size)\n",
        "\n",
        "        if(h!=None):\n",
        "            hidden_states = h\n",
        "        else:\n",
        "            hidden_states = torch.zeros(self.num_cells, batch_size, self.hidden_size)\n",
        "        \n",
        "        #hidden_states = [torch.zeros(batch_size, self.hidden_size) for _ in range(self.num_cells)]\n",
        "\n",
        "        #hidden_states = [torch.zeros(batch_size, self.hidden_size) for _ in range(self.num_cells)]\n",
        "        \n",
        "        for t in range(seq_len):\n",
        "\n",
        "            x_t = x[:,t,:]\n",
        "\n",
        "            hidden_states[0] = self.GRU_cells[0](x_t, hidden_states[0])\n",
        "\n",
        "            for l in range(1, self.num_cells):\n",
        "\n",
        "                hidden_states[l] = self.GRU_cells[l](hidden_states[l-1], hidden_states[l])\n",
        "\n",
        "\n",
        "            output_states[:,t,:] = hidden_states[self.num_cells - 1]\n",
        "\n",
        "        #output_state : [batch_size, seq_len, hidden_size]\n",
        "        return output_states, hidden_states #(così si prende output_states[:,-1,:] da dare al decoder e tutto output_states per il linear dopo il decoder)\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "3EjU7P0z1ZL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" prove\n",
        "t = torch.cat([torch.zeros(1, 2, 3) for _ in range(3)], dim = 0)\n",
        "print(t.shape)\n",
        "t[1] = torch.ones(2,3)\n",
        "print(t)\n",
        "t[-1].shape\n",
        "\n",
        "#equivalente a \n",
        "\n",
        "t = torch.stack([torch.zeros(2, 3) for _ in range(3)], dim = 0)\n",
        "print(t.shape)\n",
        "t[1] = torch.ones(2,3)\n",
        "print(t)\n",
        "t[-1].shape\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IrzUhcppwdff",
        "outputId": "a0c89c09-a339-40e6-ae45-5981d8050511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' prove\\nt = torch.cat([torch.zeros(1, 2, 3) for _ in range(3)], dim = 0)\\nprint(t.shape)\\nt[1] = torch.ones(2,3)\\nprint(t)\\nt[-1].shape\\n\\n#equivalente a \\n\\nt = torch.stack([torch.zeros(2, 3) for _ in range(3)], dim = 0)\\nprint(t.shape)\\nt[1] = torch.ones(2,3)\\nprint(t)\\nt[-1].shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUEncoderDecoder(pl.LightningModule): #oppure Seq2Seq (informiamoci sui nomi)\n",
        "    def __init__(self, special_idxs, embedding_dim = 256, hidden_size = 512, dropout = 0.2, vocabulary_size = 58, num_cells = 2):\n",
        "        super(GRUEncoderDecoder, self).__init__()\n",
        "\n",
        "        #CONTROLLARE LE DIMENSIONI\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.bos_id = special_idxs['<bos>']\n",
        "        self.eos_id = special_idxs['<eos>']\n",
        "        self.pad_id = special_idxs['<pad>']\n",
        "\n",
        "\n",
        "        print(special_idxs)\n",
        "        self.token_embedding = nn.Embedding(vocabulary_size, embedding_dim, padding_idx = self.pad_id)\n",
        "\n",
        "        self.GRU_encoder = GRU(embedding_dim, hidden_size, num_cells) \n",
        "\n",
        "        self.GRU_decoder = GRU(embedding_dim + hidden_size, hidden_size, num_cells)\n",
        "\n",
        "        self.to_logits = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
        "                                       nn.ReLU(), \n",
        "                                       nn.Dropout(dropout),\n",
        "                                       nn.Linear(hidden_size, vocabulary_size)) \n",
        "                                       \n",
        "\n",
        "        self.max_len_question = 162\n",
        "        self.max_len_answer = 32\n",
        "\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index = self.pad_id)\n",
        "\n",
        "        \n",
        "        #embedding\n",
        "    #encoder GRU\n",
        "    #decoder GRU\n",
        "    #ff per classification\n",
        "    #decoder dovrebbe poter utilizzare teacher forcing credo -> metodo inference come Transformer\n",
        "\n",
        "    def inference(self, x):\n",
        "\n",
        "        #encode and then generate the output token by token greedily\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            batch_size = x.size(0)\n",
        "            x = self.token_embedding(x)\n",
        "\n",
        "            output_encoder, previous_state = self.GRU_encoder(x)\n",
        "\n",
        "            last_state_encoder = previous_state[-1].unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "            output = torch.ones(batch_size, 1, dtype=torch.int64, device = self.device).fill_(self.bos_id)\n",
        "            done = torch.zeros(batch_size, dtype = torch.uint8, device = self.device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            for _ in range(self.max_len_answer - 1):\n",
        "                #last_state_encoder_repeated = last_state_encoder.repeat(current_output.shape[1],1,1).transpose(0,1) \n",
        "\n",
        "                    #output.shape[1] è 1, non è un problema visto che nel decoder consideriamo sempre un token\n",
        "\n",
        "                current_output = output[:,-1].unsqueeze(dim=1)\n",
        "\n",
        "                current_output_embedding = self.token_embedding(current_output)\n",
        "\n",
        "                input_decoder = torch.cat((last_state_encoder, current_output_embedding), dim=-1)\n",
        "\n",
        "                out, previous_state = self.GRU_decoder(input_decoder, previous_state)\n",
        "\n",
        "                out = self.to_logits(out)\n",
        "\n",
        "                out = torch.argmax(out[:,[-1],:], dim = -1)\n",
        "\n",
        "                output = torch.cat([output, out], dim = 1)\n",
        "\n",
        "                eos_reached = out.squeeze(1) == self.eos_id\n",
        "                done |= eos_reached\n",
        "                if done.sum() == batch_size:\n",
        "                    break\n",
        "\n",
        "            return output\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        x = self.token_embedding(x)\n",
        "\n",
        "        y = self.token_embedding(y)\n",
        "\n",
        "        print(f\"shape x {x.shape}\")\n",
        "        print(f\"shape y {y.shape}\")\n",
        "\n",
        "\n",
        "        output_encoder, state_encoder = self.GRU_encoder(x) \n",
        "\n",
        "        print(f\"shape output_encoder {output_encoder.shape}\")\n",
        "        print(f\"shape state_encoder {state_encoder.shape}\")\n",
        "\n",
        "        last_state_encoder = state_encoder[-1]\n",
        "\n",
        "        print(f\"shape last_state_encoder {last_state_encoder.shape}\")\n",
        "        #state_encoder = self.GRU_encoder(x)[:,-1,:]\n",
        "\n",
        "        last_state_encoder_repeated = last_state_encoder.repeat(y.shape[1],1,1).transpose(0,1) #CONTROLLA\n",
        "\n",
        "        print(f\"shape last_state_encoder_repeated {last_state_encoder_repeated.shape}\")\n",
        "\n",
        "        input_decoder = torch.cat((last_state_encoder_repeated, y), dim=-1)\n",
        "\n",
        "        print(f\"shape input_decoder {input_decoder.shape}\")\n",
        "        output_decoder, _ = self.GRU_decoder(input_decoder, state_encoder)\n",
        "\n",
        "        print(f\"shape output_decoder {output_decoder.shape}\")\n",
        "        return self.to_logits(output_decoder).transpose(1,2)\n",
        "        \n",
        "    \n",
        "    def configure_optimizers(self):# learning rate = 1x10^-4; beta1 =0.9; beta2 = 0.995 dal paper\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4, betas=(0.9, 0.995))\n",
        "    \n",
        "        pass\n",
        "\n",
        "    def training_step(self, batch, batch_idx):#DOVREBBE RIMANERE COSì\n",
        "        x, y = batch\n",
        "        y_pred = self(x, y)\n",
        "        loss = F.cross_entropy(y_pred, y, ignore_index = self.pad_id)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):#DOVREBBE RIMANERE COSì\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.accuracy.update(y_pred, y)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):#DOVREBBE RIMANERE COSì\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.accuracy.update(y_pred, y)\n",
        "\n",
        "    def validation_epoch_end(self, outputs):#DOVREBBE RIMANERE COSì\n",
        "        self.log('accuracy_epoch', self.accuracy.compute())\n",
        "        self.accuracy.reset()\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "wR-AsURhRoYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.setup(\"\")\n",
        "train_loader = dm.train_dataloader()\n",
        "x = next(iter(train_loader))\n"
      ],
      "metadata": {
        "id": "zVsP5tsa6coT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfy4V8Eo7Swq",
        "outputId": "33282c27-ad09-4b7b-de70-900d41472173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 1, 48, 44,  ...,  0,  0,  0],\n",
              "         [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "         [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "         [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "         [ 1, 48, 44,  ...,  0,  0,  0]]),\n",
              " tensor([[ 1, 20,  2,  ...,  0,  0,  0],\n",
              "         [ 1, 16, 15,  ...,  0,  0,  0],\n",
              "         [ 1, 19, 22,  ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [ 1, 12, 20,  ...,  0,  0,  0],\n",
              "         [ 1, 18, 18,  ...,  0,  0,  0],\n",
              "         [ 1, 12, 19,  ...,  0,  0,  0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root_dir = \"./training/GRU/checkpoints\"\n",
        "logger_dir = \"./training/GRU/tensorboard/logs\"\n",
        "checkpoint_dir = \"./training/GRU/checkpoints/gru_seq2seq_checkpoints\"\n",
        "\n",
        "EPOCHS = 2\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "EMBEDDING_DIM = 256\n",
        "NUM_HEADS = 8\n",
        "HIDDEN_SIZE = 512\n",
        "DROP_PROB = 0.2\n",
        "NUM_CELLS = 2\n",
        "SPECIAL_CHAR_DICT = {'<bos>': vocabulary['<bos>'], '<eos>': vocabulary['<eos>'], '<pad>': vocabulary['<pad>']}\n",
        "\n",
        "\n",
        "ADDITIONAL_EPOCHS = 5"
      ],
      "metadata": {
        "id": "6iZMdPxoKcCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq = GRUEncoderDecoder(\n",
        "    SPECIAL_CHAR_DICT, embedding_dim = EMBEDDING_DIM, hidden_size = HIDDEN_SIZE, \n",
        "    dropout = DROP_PROB, vocabulary_size = len(vocabulary), num_cells = NUM_CELLS\n",
        "    )\n"
      ],
      "metadata": {
        "id": "MWv_MnqvMAGX",
        "outputId": "245c0c32-cc2b-4d1b-fe43-0514aa436df8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<bos>': 1, '<eos>': 2, '<pad>': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "id": "2qtWABaBN2HY",
        "outputId": "21f68ab6-ee20-41b2-cb2e-82cc2a96cb87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 48, 44,  ...,  0,  0,  0],\n",
              "        [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "        [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "        [ 1, 48, 44,  ...,  0,  0,  0],\n",
              "        [ 1, 48, 44,  ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq(x[0], x[1]).shape"
      ],
      "metadata": {
        "id": "A4QZZ7bdNojI",
        "outputId": "919ee20f-e2cb-457e-e009-3c5b5d6714a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape x torch.Size([64, 162, 256])\n",
            "shape y torch.Size([64, 32, 256])\n",
            "shape output_encoder torch.Size([64, 162, 512])\n",
            "shape state_encoder torch.Size([2, 64, 512])\n",
            "shape last_state_encoder torch.Size([64, 512])\n",
            "shape last_state_encoder_repeated torch.Size([64, 32, 512])\n",
            "shape input_decoder torch.Size([64, 32, 768])\n",
            "shape output_decoder torch.Size([64, 32, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 58, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(gru_seq2seq(x[0], x[1]), x[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwRh0DP9BCQP",
        "outputId": "25c4ece4-3eb3-4f14-cb76-c34a1f4c3874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape x torch.Size([64, 162, 256])\n",
            "shape y torch.Size([64, 32, 256])\n",
            "shape output_encoder torch.Size([64, 162, 512])\n",
            "shape state_encoder torch.Size([2, 64, 512])\n",
            "shape last_state_encoder torch.Size([64, 512])\n",
            "shape last_state_encoder_repeated torch.Size([64, 32, 512])\n",
            "shape input_decoder torch.Size([64, 32, 768])\n",
            "shape output_decoder torch.Size([64, 32, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.0678, grad_fn=<NllLoss2DBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq.inference(x[0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAmGlWfUMS5y",
        "outputId": "2e0e61a9-852c-4327-94dd-29475ee9f8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "logger = TensorBoardLogger(logger_dir, name=\"GRU_SEQ2SEQ\", log_graph=True)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir,\n",
        "    filename='gru_seq2seq_{epoch:02d}_{step:06d}',\n",
        "    save_top_k=3,\n",
        "    monitor='accuracy_epoch',\n",
        "    mode='max',\n",
        "    save_last=True\n",
        ")\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "trainer = pl.Trainer(default_root_dir=root_dir, accelerator='cpu', devices=1, gradient_clip_val = 0.1, max_epochs = EPOCHS, logger = logger, callbacks = callbacks)\n",
        "math_dm = Mathematics_DataModule(['algebra__linear_1d'], batch_size = BATCH_SIZE)\n",
        "trainer.fit(gru_seq2seq, datamodule = math_dm)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hi_Pt0RcK3PF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8c44b41e-cbf1-49c2-c353-c2a7a481ec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlogger = TensorBoardLogger(logger_dir, name=\"GRU_SEQ2SEQ\", log_graph=True)\\ncheckpoint_callback = ModelCheckpoint(\\n    dirpath = checkpoint_dir,\\n    filename=\\'gru_seq2seq_{epoch:02d}_{step:06d}\\',\\n    save_top_k=3,\\n    monitor=\\'accuracy_epoch\\',\\n    mode=\\'max\\',\\n    save_last=True\\n)\\ncallbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\\ntrainer = pl.Trainer(default_root_dir=root_dir, accelerator=\\'cpu\\', devices=1, gradient_clip_val = 0.1, max_epochs = EPOCHS, logger = logger, callbacks = callbacks)\\nmath_dm = Mathematics_DataModule([\\'algebra__linear_1d\\'], batch_size = BATCH_SIZE)\\ntrainer.fit(gru_seq2seq, datamodule = math_dm)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "da fare:\n",
        "\n",
        "-  utilizzare stage (parametro di setup) per caricare anche un solo dataset se stage = \"train\" ad esempio \n",
        "   (https://colab.research.google.com/drive/1oJrA-Q-neOl1fCQJhIWR_GmxpYaG-cFx?authuser=1#scrollTo=JM57yq7bJS0E)\n",
        "\n",
        "-  aggiungere predict_step nel pl.LightningModule dove si chiama inference e relativo predict dataloader nel Lightning data module\n",
        "\n",
        "\n",
        "-  RNN fatte molto bene:\n",
        "    https://github.com/georgeyiasemis/Recurrent-Neural-Networks-from-scratch-using-PyTorch \n",
        "    https://towardsdatascience.com/building-a-lstm-by-hand-on-pytorch-59c02a4ec091\n",
        "    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "S0igWQqiZV5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2bbda23d-7642-4d26-eb91-49b0e2140576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nda fare:\\n\\n-  utilizzare stage (parametro di setup) per caricare anche un solo dataset se stage = \"train\" ad esempio \\n   (https://colab.research.google.com/drive/1oJrA-Q-neOl1fCQJhIWR_GmxpYaG-cFx?authuser=1#scrollTo=JM57yq7bJS0E)\\n\\n-  aggiungere predict_step nel pl.LightningModule dove si chiama inference e relativo predict dataloader nel Lightning data module\\n\\n\\n-  RNN fatte molto bene:\\n    https://github.com/georgeyiasemis/Recurrent-Neural-Networks-from-scratch-using-PyTorch \\n    https://towardsdatascience.com/building-a-lstm-by-hand-on-pytorch-59c02a4ec091\\n    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5xiDjT3MBjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU Modules"
      ],
      "metadata": {
        "id": "QVGB7UiiMB6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "da fare:\n",
        "\n",
        "-  controllare l'architettura GRU (FATTO)\n",
        "\n",
        "-  controllare teacher forcing (FATTO)\n",
        "\n",
        "\n",
        "\n",
        "-  utilizzare stage (parametro di setup) per caricare anche un solo dataset se stage = \"train\" ad esempio \n",
        "   (https://colab.research.google.com/drive/1oJrA-Q-neOl1fCQJhIWR_GmxpYaG-cFx?authuser=1#scrollTo=JM57yq7bJS0E)\n",
        "\n",
        "-  aggiungere predict_step nel pl.LightningModule dove si chiama inference e relativo predict dataloader nel Lightning data module\n",
        "\n",
        "\n",
        "-  RNN fatte molto bene:\n",
        "    https://github.com/georgeyiasemis/Recurrent-Neural-Networks-from-scratch-using-PyTorch \n",
        "    https://towardsdatascience.com/building-a-lstm-by-hand-on-pytorch-59c02a4ec091\n",
        "    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n"
      ],
      "metadata": {
        "id": "KkLLQqqQMB6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wx = nn.Linear(input_size, 3*hidden_size, bias=True)\n",
        "        self.Wh_gate = nn.Linear(hidden_size, 2*hidden_size, bias=True)\n",
        "\n",
        "        self.Whh = nn.Linear(hidden_size, hidden_size, bias = True)\n",
        "\n",
        "        \n",
        "        #nell'implementazione del git c'è anche una funzione reset_parameters\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        x_reset, x_update, x_candidate = torch.tensor_split(self.Wx(x), 3, dim=-1)\n",
        "        \"\"\"\n",
        "        print(f\"shape h {h.shape}\")\n",
        "        print(f\"shape {x.shape}\")\n",
        "        print(f\"hidden_size {self.hidden_size}\")\n",
        "        print(f\"input_size {self.input_size}\")\n",
        "        \"\"\"\n",
        "        #h = h.clone()           #INSERITO\n",
        "\n",
        "        h_reset, h_update = torch.tensor_split(self.Wh_gate(h), 2, dim=-1)\n",
        "\n",
        "        reset_gate = torch.sigmoid(x_reset + h_reset)\n",
        "\n",
        "        update_gate = torch.sigmoid(x_update + h_update)\n",
        "\n",
        "        h_candidate = torch.tanh(x_candidate + self.Whh(reset_gate * h))   \n",
        "\n",
        "        h_t = update_gate * h + (1-update_gate) * h_candidate\n",
        "\n",
        "        return h_t\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VtfWqeUlMB6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    \n",
        "    def __init__ (self, input_size, hidden_size, num_cells=2, device=None):\n",
        "        assert num_cells>0\n",
        "\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.num_cells = num_cells\n",
        "        \n",
        "\n",
        "        self.GRU_cells = nn.ModuleList(\n",
        "            [GRUCell(input_size, hidden_size)]+[GRUCell(hidden_size, hidden_size) for _ in range(1, num_cells)])\n",
        "        \n",
        "    def forward(self, x, h=None):\n",
        "        \"x è una sequenza [batch, seq_len, embedding_dim]\"\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        \"h [self.num_cells, batch_size, self.hidden_size]\"\n",
        "        #output_states = torch.stack([torch.zeros(batch_size, self.hidden_size) for _ in range(seq_len)], dim = 0)\n",
        "        output_states = torch.zeros((batch_size, seq_len, self.hidden_size), device=x.device)\n",
        "\n",
        "        #print(self.device)\n",
        "        #print(f\"output_states device {output_states.device}\")\n",
        "\n",
        "        if(h!=None):\n",
        "            hidden_states = h\n",
        "        else:\n",
        "            #hidden_states = torch.zeros((self.num_cells, batch_size, self.hidden_size), device=x.device)\n",
        "            hidden_states = [torch.zeros((batch_size, self.hidden_size), device=x.device) for _ in range(self.num_cells)]\n",
        "\n",
        "        #print(f\"hidden_states device {hidden_states.device}\")\n",
        "\n",
        "        \n",
        "        #hidden_states = [torch.zeros(batch_size, self.hidden_size) for _ in range(self.num_cells)]\n",
        "\n",
        "        #hidden_states = [torch.zeros(batch_size, self.hidden_size) for _ in range(self.num_cells)]\n",
        "        \n",
        "        for t in range(seq_len):\n",
        "\n",
        "            x_t = x[:,t,:]\n",
        "\n",
        "            #hidden_states = hidden_states.clone()\n",
        "\n",
        "            hidden_states[0] = self.GRU_cells[0](x_t, hidden_states[0])\n",
        "\n",
        "            for l in range(1, self.num_cells):\n",
        "                #hidden_states = hidden_states.clone()\n",
        "\n",
        "                hidden_states[l] = self.GRU_cells[l](hidden_states[l-1], hidden_states[l])\n",
        "\n",
        "            #output_states = output_states.clone()\n",
        "\n",
        "            output_states[:,t,:] = hidden_states[self.num_cells - 1]\n",
        "\n",
        "        #output_state : [batch_size, seq_len, hidden_size]\n",
        "        return output_states, hidden_states #(così si prende output_states[:,-1,:] da dare al decoder e tutto output_states per il linear dopo il decoder)\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "QtjxQD_bMB6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" prove\n",
        "t = torch.cat([torch.zeros(1, 2, 3) for _ in range(3)], dim = 0)\n",
        "print(t.shape)\n",
        "t[1] = torch.ones(2,3)\n",
        "print(t)\n",
        "t[-1].shape\n",
        "\n",
        "#equivalente a \n",
        "\n",
        "t = torch.stack([torch.zeros(2, 3) for _ in range(3)], dim = 0)\n",
        "print(t.shape)\n",
        "t[1] = torch.ones(2,3)\n",
        "print(t)\n",
        "t[-1].shape\n",
        "\"\"\""
      ],
      "metadata": {
        "outputId": "a8a5980c-210a-4300-9b89-6a38dd1a2fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "_BA0eHw5MB6O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' prove\\nt = torch.cat([torch.zeros(1, 2, 3) for _ in range(3)], dim = 0)\\nprint(t.shape)\\nt[1] = torch.ones(2,3)\\nprint(t)\\nt[-1].shape\\n\\n#equivalente a \\n\\nt = torch.stack([torch.zeros(2, 3) for _ in range(3)], dim = 0)\\nprint(t.shape)\\nt[1] = torch.ones(2,3)\\nprint(t)\\nt[-1].shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUEncoderDecoder(pl.LightningModule): #oppure Seq2Seq (informiamoci sui nomi)\n",
        "    def __init__(self,\n",
        "        special_idxs: Dict[str, int],\n",
        "        optimizer_params: dict,\n",
        "        learning_rate: float=1e-4,\n",
        "        embedding_dim: float=256,\n",
        "        hidden_size: int=512,\n",
        "        vocabulary_size: int=58,\n",
        "        max_len_question: int=162,\n",
        "        max_len_answer: int=32,\n",
        "        num_cells: int=2,\n",
        "        dropout: float=0.2,\n",
        "    ):\n",
        "        super(GRUEncoderDecoder, self).__init__()\n",
        "\n",
        "        #CONTROLLARE LE DIMENSIONI\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.bos_id = special_idxs['<bos>']\n",
        "        self.eos_id = special_idxs['<eos>']\n",
        "        self.pad_id = special_idxs['<pad>']\n",
        "\n",
        "        self.optimizer_params = optimizer_params\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocabulary_size, embedding_dim, padding_idx = self.pad_id)\n",
        "\n",
        "        self.GRU_encoder = GRU(embedding_dim, hidden_size, num_cells) \n",
        "\n",
        "        self.GRU_decoder = GRU(embedding_dim + hidden_size, hidden_size, num_cells)\n",
        "\n",
        "        self.to_logits = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
        "                                       nn.ReLU(), \n",
        "                                       nn.Dropout(dropout),\n",
        "                                       nn.Linear(hidden_size, vocabulary_size)) \n",
        "        \n",
        "        self.max_len_question = max_len_question\n",
        "        self.max_len_answer = max_len_answer\n",
        "\n",
        "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "        self.test_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index=self.pad_id)\n",
        "\n",
        "\n",
        "        \n",
        "        #embedding\n",
        "    #encoder GRU\n",
        "    #decoder GRU\n",
        "    #ff per classification\n",
        "    #decoder dovrebbe poter utilizzare teacher forcing credo -> metodo inference come Transformer\n",
        "\n",
        "    def inference(self, x):\n",
        "\n",
        "        #encode and then generate the output token by token greedily\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            batch_size = x.size(0)\n",
        "            x = self.token_embedding(x)\n",
        "\n",
        "            #print(f\"x device {x.device}\")\n",
        "\n",
        "            output_encoder, previous_state = self.GRU_encoder(x)\n",
        "\n",
        "            #print(f\"output_encoder device {output_encoder.device}\")\n",
        "            #print(f\"previous_state device {output_encoder.device}\")\n",
        "\n",
        "\n",
        "            last_state_encoder = previous_state[-1].unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "            output = torch.ones(batch_size, 1, dtype=torch.int64, device = self.device).fill_(self.bos_id)\n",
        "            done = torch.zeros(batch_size, dtype = torch.uint8, device = self.device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            for _ in range(self.max_len_answer - 1):\n",
        "                #last_state_encoder_repeated = last_state_encoder.repeat(current_output.shape[1],1,1).transpose(0,1) \n",
        "\n",
        "                    #output.shape[1] è 1, non è un problema visto che nel decoder consideriamo sempre un token\n",
        "\n",
        "                current_output = output[:,-1].unsqueeze(dim=1)\n",
        "\n",
        "                current_output_embedding = self.token_embedding(current_output)\n",
        "\n",
        "                input_decoder = torch.cat((last_state_encoder, current_output_embedding), dim=-1)\n",
        "\n",
        "                out, previous_state = self.GRU_decoder(input_decoder, previous_state)\n",
        "\n",
        "                out = self.to_logits(out)\n",
        "\n",
        "                out = torch.argmax(out[:,[-1],:], dim = -1)\n",
        "\n",
        "                output = torch.cat([output, out], dim = 1)\n",
        "\n",
        "                eos_reached = out.squeeze(1) == self.eos_id\n",
        "                done |= eos_reached\n",
        "                if done.sum() == batch_size:\n",
        "                    break\n",
        "\n",
        "            return output\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        x = self.token_embedding(x)\n",
        "\n",
        "        y = self.token_embedding(y)\n",
        "\n",
        "        #print(f\"shape x {x.shape}\")\n",
        "        #print(f\"shape y {y.shape}\")\n",
        "\n",
        "\n",
        "        output_encoder, state_encoder = self.GRU_encoder(x) \n",
        "\n",
        "        #print(f\"shape output_encoder {output_encoder.shape}\")\n",
        "        #print(f\"shape state_encoder {state_encoder.shape}\")\n",
        "\n",
        "        last_state_encoder = state_encoder[-1]\n",
        "\n",
        "        #print(f\"shape last_state_encoder {last_state_encoder.shape}\")\n",
        "        #state_encoder = self.GRU_encoder(x)[:,-1,:]\n",
        "\n",
        "        last_state_encoder_repeated = last_state_encoder.repeat(y.shape[1],1,1).transpose(0,1) #CONTROLLA\n",
        "\n",
        "        #print(f\"shape last_state_encoder_repeated {last_state_encoder_repeated.shape}\")\n",
        "\n",
        "        input_decoder = torch.cat((last_state_encoder_repeated, y), dim=-1)\n",
        "\n",
        "        #print(f\"shape input_decoder {input_decoder.shape}\")\n",
        "        output_decoder, _ = self.GRU_decoder(input_decoder, state_encoder)\n",
        "\n",
        "        #print(f\"shape output_decoder {output_decoder.shape}\")\n",
        "        return self.to_logits(output_decoder).transpose(1,2)\n",
        "        \n",
        "    \n",
        "    def configure_optimizers(self):# learning rate = 1x10^-4; beta1 =0.9; beta2 = 0.995 dal paper\n",
        "        betas = self.optimizer_params['betas']\n",
        "        return torch.optim.Adam(self.parameters(), self.learning_rate, betas)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self(x, y)\n",
        "        loss = F.cross_entropy(y_pred, y, ignore_index = self.pad_id)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        self.train_accuracy.update(y_pred, y)\n",
        "        self.log('train_accuracy_epoch', self.train_accuracy.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.val_accuracy.update(y_pred, y)\n",
        "        self.log('val_accuracy_step', self.val_accuracy.compute(), on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x)  #[batch_size, max_eos_found]\n",
        "        y_pred = F.pad(y_pred, (0, self.max_len_answer - y_pred.shape[1]), mode='constant', value=self.pad_id) #[batch_size, max_len_answer]\n",
        "        self.test_accuracy.update(y_pred, y)\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('val_accuracy_epoch', self.val_accuracy.compute(), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.val_accuracy.reset()\n",
        "        \n",
        "        # Also reset the training accuracy\n",
        "        self.train_accuracy.reset()\n",
        "\n",
        "    \n",
        "    def test_epoch_end(self, outputs):\n",
        "        self.log('test_accuracy_epoch', self.test_accuracy.compute(), on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.test_accuracy.reset()\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "zB2OWi5uMB6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDCWfYaeMEyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NON SOTA (GRU)"
      ],
      "metadata": {
        "id": "X963rmZkD9_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "dm.setup(\"\")\n",
        "train_loader = dm.train_dataloader()\n",
        "x = next(iter(train_loader))\n",
        "\"\"\""
      ],
      "metadata": {
        "outputId": "d109f690-8560-487a-f534-a910adf541e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0GzRsPpuMGV1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndm.setup(\"\")\\ntrain_loader = dm.train_dataloader()\\nx = next(iter(train_loader))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x"
      ],
      "metadata": {
        "id": "0JQF9-7EMGV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = v"
      ],
      "metadata": {
        "id": "adgjWnpxEYQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"./training/GRU/checkpoints\"\n",
        "logger_dir = \"./training/GRU/tensorboard/logs\"\n",
        "checkpoint_dir = \"./training/GRU/checkpoints/gru_seq2seq_checkpoints\"\n",
        "\n",
        "\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 128\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "# HIDDEN_SIZE = 2048\n",
        "HIDDEN_SIZE = 512\n",
        "DROP_PROB = 0.2\n",
        "GRADIENT_CLIP_VAL = 0.1\n",
        "NUM_CELLS = 2\n",
        "SPECIAL_CHAR_DICT = {'<bos>': vocabulary['<bos>'], '<eos>': vocabulary['<eos>'], '<pad>': vocabulary['<pad>']}\n",
        "OPTIMIZER_PARAMS = {'betas': (0.9, 0.995)}\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WWl2phutMGV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_hyperparams = {\n",
        "    \"special_idxs\": SPECIAL_CHAR_DICT,\n",
        "    \"optimizer_params\": OPTIMIZER_PARAMS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"embedding_dim\": EMBEDDING_DIM,\n",
        "    \"hidden_size\": HIDDEN_SIZE,\n",
        "    \"vocabulary_size\": len(vocabulary),\n",
        "    \"num_cells\": NUM_CELLS,\n",
        "    \"dropout\": DROP_PROB#,\n",
        "    #\"device\" : device\n",
        "    }\n",
        "\n",
        "logger = TensorBoardLogger(logger_dir, name=\"GRU\")\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir,\n",
        "    filename='GRU_{epoch:02d}_{step:06d}_{val_accuracy_epoch:.3f}',\n",
        "    save_top_k=6,\n",
        "    monitor='val_accuracy_epoch',\n",
        "    mode='max',\n",
        "    verbose=True,\n",
        "    save_last=True\n",
        ")\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "trainer_hyperparams = {\n",
        "    \"default_root_dir\": root_dir,\n",
        "    \"accelerator\": \"auto\",\n",
        "    \"devices\": 1,\n",
        "    \"precision\": 16, # ADDED\n",
        "    \"log_every_n_steps\": 10,\n",
        "    # \"val_check_interval\": 0.5, # validation step called 2 times during a training epoch\n",
        "    \"val_check_interval\": 1.0, \n",
        "    \"gradient_clip_val\": GRADIENT_CLIP_VAL,\n",
        "    \"max_epochs\": EPOCHS,\n",
        "    \"logger\": logger,\n",
        "    \"callbacks\": callbacks,\n",
        "    # \"deterministic\": True,\n",
        "}\n",
        "\n",
        "modules = ['algebra__linear_1d', 'probability__swr_p_level_set', 'numbers__is_prime']\n",
        "# modules = ['algebra__linear_1d']\n",
        "math_dm = Mathematics_DataModule(modules, difficulty=['train-easy'], batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Rzd0sHINEwC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq = GRUEncoderDecoder(**GRU_hyperparams)\n",
        "\n",
        "\n",
        "trainer = Trainer(**trainer_hyperparams)\n",
        "\n",
        "trainer.fit(gru_seq2seq, datamodule=math_dm)"
      ],
      "metadata": {
        "outputId": "2de52785-7fa4-4b58-eb85-701ef103317a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "b3ec835c5e8946308b6bccf98407124a",
            "1d82e1ed61b4457184d4010dcfffd2fd",
            "670c638686bf495895dcea219d992a40",
            "9d01483a05c34571ab441121dc93dcd3",
            "d1e00811e4d44ea082f6e6b1765ae473",
            "95b6d0ec3768407088613dcf362073fe",
            "c33580ef7d0d40c58a5912c3b504e467",
            "d78d218ee49c43bea641b6013758f4e9",
            "cec9fae34289451e8f2df7d4bf126e3b",
            "aceda7f5aabd4d4a99ead462f76bb101",
            "14b758dc03ea4c0496f110f2d71530f2",
            "3f663fcb433a4e6cac2774e6fed0cfdf",
            "6bc0f57de39e47478041300cbf295fc6",
            "7cd51b306c9444c2b18a496e9410b159",
            "58386b63300a45eeb1ef140bc7badf5d",
            "796552f7f3194ec7bc58afa1b46aa47d",
            "90944a5d0af64b41b15e7fa68d32ef55",
            "b6551257fe5a4e258821384dec72945f",
            "f6638d21618141258401ab5f919ddb01",
            "6349a0baf85b484baf8e7f0f8173ec7c",
            "7faf0df8d7924ffe88f665761fe4079c",
            "cdb560d18a0d47ce92e77acf88f614b1",
            "64b07cb62ad74d19a42c57df6ebe61e2",
            "a95b29cf8de4433fbc7063e59be01393",
            "3ff44f3198b143e4a9db1dc98208ace5",
            "ac51ef993ebc4fa692f602079d4e0b36",
            "8e1dc14ec0d54ed78785a16025bd71c2",
            "8a182c2b563e4a5d9dc66a80d77303f1",
            "dcf0ed117076491b81a377239a7f69ec",
            "9e96a762f3d94d3c9a7376a6196d64a6",
            "24cb86c6ce4a4a269ce4259a6cf33b45",
            "58cd248f72ca40c8b77b53d0fb1d6799",
            "0c6bec20590f4bd88a5db2a0db3d93bc",
            "343a753e386546eab07cc88aaaef4c41",
            "a2eb3c3fafe448ff924c8b635bb32219",
            "034b2106787b4be2bfd4df60cf5c1a84",
            "fb57bec1491a4b20844155e3a75b83a9",
            "910398eba7d244679745baf1d9876a27",
            "3d0eb589435f4ac6adc61ad07e5a1162",
            "657fe5c16933497796e95192480d1719",
            "be4b5bdd69554f068827ad5f3937e82d",
            "7e6f99d71ec74b67ba6a674265c1f093",
            "2362bcbf1fe847779582919b4853085d",
            "bb87206bf61e4bd38d079c7bac2a3b26"
          ]
        },
        "id": "qsOQXljYMGWC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type               | Params\n",
            "-------------------------------------------------------\n",
            "0 | token_embedding | Embedding          | 14.8 K\n",
            "1 | GRU_encoder     | GRU                | 2.8 M \n",
            "2 | GRU_decoder     | GRU                | 3.5 M \n",
            "3 | to_logits       | Sequential         | 292 K \n",
            "4 | train_accuracy  | MulticlassAccuracy | 0     \n",
            "5 | val_accuracy    | MulticlassAccuracy | 0     \n",
            "6 | test_accuracy   | MulticlassAccuracy | 0     \n",
            "-------------------------------------------------------\n",
            "6.6 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.6 M     Total params\n",
            "26.444    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3ec835c5e8946308b6bccf98407124a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f663fcb433a4e6cac2774e6fed0cfdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64b07cb62ad74d19a42c57df6ebe61e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 1: 'val_accuracy_epoch' reached 0.42857 (best 0.42857), saving model to '/content/drive/.shortcut-targets-by-id/1IS7xxoH06-zPLbTk07CAGSmtMTFE85h_/Deep_Learning_Project/training/GRU/checkpoints/gru_seq2seq_checkpoints/GRU_epoch=00_step=000001_val_accuracy_epoch=0.429.ckpt' as top 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "343a753e386546eab07cc88aaaef4c41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 2: 'val_accuracy_epoch' reached 0.28571 (best 0.42857), saving model to '/content/drive/.shortcut-targets-by-id/1IS7xxoH06-zPLbTk07CAGSmtMTFE85h_/Deep_Learning_Project/training/GRU/checkpoints/gru_seq2seq_checkpoints/GRU_epoch=01_step=000002_val_accuracy_epoch=0.286.ckpt' as top 6\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "3e10fed0-afa8-48cd-9001-33366af7e2db",
        "id": "mRTgvMLdMGWE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-2f755f117ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq(x[0], x[1]).shape"
      ],
      "metadata": {
        "id": "fQCWeHIyMGWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(gru_seq2seq(x[0], x[1]), x[1])"
      ],
      "metadata": {
        "id": "0jZMFfvMMGWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_seq2seq.inference(x[0]).shape"
      ],
      "metadata": {
        "id": "zzPN_YVzMGWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "logger = TensorBoardLogger(logger_dir, name=\"GRU_SEQ2SEQ\", log_graph=True)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = checkpoint_dir,\n",
        "    filename='gru_seq2seq_{epoch:02d}_{step:06d}',\n",
        "    save_top_k=3,\n",
        "    monitor='accuracy_epoch',\n",
        "    mode='max',\n",
        "    save_last=True\n",
        ")\n",
        "callbacks = [checkpoint_callback, TQDMProgressBar(refresh_rate=20)]\n",
        "trainer = pl.Trainer(default_root_dir=root_dir, accelerator='cpu', devices=1, gradient_clip_val = 0.1, max_epochs = EPOCHS, logger = logger, callbacks = callbacks)\n",
        "math_dm = Mathematics_DataModule(['algebra__linear_1d'], batch_size = BATCH_SIZE)\n",
        "trainer.fit(gru_seq2seq, datamodule = math_dm)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cAwWkv84MGWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "da fare:\n",
        "\n",
        "-  utilizzare stage (parametro di setup) per caricare anche un solo dataset se stage = \"train\" ad esempio \n",
        "   (https://colab.research.google.com/drive/1oJrA-Q-neOl1fCQJhIWR_GmxpYaG-cFx?authuser=1#scrollTo=JM57yq7bJS0E)\n",
        "\n",
        "-  aggiungere predict_step nel pl.LightningModule dove si chiama inference e relativo predict dataloader nel Lightning data module\n",
        "\n",
        "\n",
        "-  RNN fatte molto bene:\n",
        "    https://github.com/georgeyiasemis/Recurrent-Neural-Networks-from-scratch-using-PyTorch \n",
        "    https://towardsdatascience.com/building-a-lstm-by-hand-on-pytorch-59c02a4ec091\n",
        "    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Y2sBCexZMGWM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}