{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiantonelli/DeepLearning-Project/blob/main/Deep_Learning_Project_Antonelli_Cuconasu_Gaudenzi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "_0HXoR9RpcO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fxGf0hOgnsPD",
        "outputId": "8c58560d-7fe8-4bc9-99ac-e554fd77fe3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.4/826.4 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install gdown==4.5.4 --no-cache-dir --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchmetrics\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle as pkl\n",
        "from tqdm.notebook import tqdm\n",
        "import pytorch_lightning as pl \n",
        "import math\n",
        "from math import sqrt\n",
        "import pickle\n",
        "from typing import *\n",
        "import gdown"
      ],
      "metadata": {
        "id": "DobcczcWqek-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "url = \"https://drive.google.com/drive/folders/1-6MRkFoSSRJqeKgcMXm3PeA159KzHuB_?usp=sharing\"\n",
        "gdown.download_folder(url = url, quiet = True, use_cookies = False, remaining_ok=True)\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNGXDrHt71Y",
        "outputId": "ce0905eb-c3a7-4fce-d67d-2028f2270400"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/DeepLearningProject-Shared\"\n",
        "dataset_folder_path = \"/content/drive/MyDrive/Deep_Learning_Project\"\n",
        "os.chdir(dataset_folder_path)"
      ],
      "metadata": {
        "id": "gDIk7qc1uP4g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset (NON ESEGUIRE)"
      ],
      "metadata": {
        "id": "P4AfeDpYq3dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmbglL0Yt7yu",
        "outputId": "d51ff8dc-4061-4ce6-c7f2-4fdf0c331605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algebra__linear_1d  datasets  mathematics_dataset-v1.0\tmodules.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ve_GZkJh8TAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    with open(text_path) as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            if lowercase:\n",
        "                if idx % 2 == 0: # Questions\n",
        "                    questions.append(line.rstrip().lower()) \n",
        "                else:\n",
        "                    answers.append(line.rstrip().lower())\n",
        "\n",
        "    return questions, answers"
      ],
      "metadata": {
        "id": "8v1Y18AQt7wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(lists_of_texts: List[List[str]]):\n",
        "    unified_text = []\n",
        "    \n",
        "    for l in lists_of_texts:\n",
        "        unified_text += l\n",
        "\n",
        "    return Counter(\" \".join(unified_text)).keys()"
      ],
      "metadata": {
        "id": "lYe9h3nL2ef0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "# Get all files\n",
        "folders = ['extrapolate', 'interpolate', 'train-easy', 'train-medium', 'train-hard']\n",
        "files = []\n",
        "\n",
        "for fold in folders:\n",
        "    files += glob.glob(f\"./mathematics_dataset-v1.0/{fold}/*.txt\")"
      ],
      "metadata": {
        "id": "0dvxsrOv8jev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ8XDzZhDqiy",
        "outputId": "f71095af-44fa-49e3-8990-5653475f42d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./mathematics_dataset-v1.0/extrapolate/arithmetic__add_sub_multiple_longer.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/algebra__polynomial_roots_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__add_or_sub_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__div_big.txt',\n",
              " './mathematics_dataset-v1.0/extrapolate/arithmetic__mul_div_multiple_longer.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {}\n",
        "all_lists = []"
      ],
      "metadata": {
        "id": "6STsKEUWF3Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for f in files:\n",
        "    train, test = read_dataset(f)\n",
        "    all_lists += train\n",
        "    all_lists += test\n",
        "\n",
        "    vocabulary = vocabulary | get_vocabulary(all_lists)\n",
        "    all_lists = []\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        #with open('./datasets/vocabulary.pkl', 'wb') as f:\n",
        "            pickle.dump(vocabulary, f)"
      ],
      "metadata": {
        "id": "FUejIWdZGnPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary"
      ],
      "metadata": {
        "id": "BQ2P_Vw3HKkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST"
      ],
      "metadata": {
        "id": "8MYiPaStYKbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./datasets/vocabulary.pkl', 'rb') as f:\n",
        "    vo = pickle.load(f)"
      ],
      "metadata": {
        "id": "jM-I-ODQOcUw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = vo"
      ],
      "metadata": {
        "id": "A9Hzt8oUOjBS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SWv7XaOEGqJ",
        "outputId": "7b8db0e7-4181-452f-b64b-ad044b4e8bab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(all_lists)"
      ],
      "metadata": {
        "id": "xr-Lz5ndDvTW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls ./mathematics_dataset-v1.0/train-easy"
      ],
      "metadata": {
        "id": "xPQ2uETGBBB_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algebra_path = \"./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt\"\n",
        "probability_path = \"./mathematics_dataset-v1.0/train-easy/probability__swr_p_level_set.txt\"\n",
        "prime_path = \"./mathematics_dataset-v1.0/train-easy/numbers__is_prime.txt\""
      ],
      "metadata": {
        "id": "NubFUsQo0TM2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "questions_easy_algebra, answers_easy_algebra = read_dataset(algebra_path)\n",
        "questions_easy_probability, answers_easy_probability = read_dataset(probability_path)\n",
        "questions_easy_prime, answers_easy_prime = read_dataset(prime_path)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qfOfAYIh08FD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a38f0138-8a45-4819-e6ef-6196ff1da07f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nquestions_easy_algebra, answers_easy_algebra = read_dataset(algebra_path)\\nquestions_easy_probability, answers_easy_probability = read_dataset(probability_path)\\nquestions_easy_prime, answers_easy_prime = read_dataset(prime_path)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from collections import Counter\n",
        "#lis = \" \".join(questions_easy_prime)\n",
        "#Counter(lis)"
      ],
      "metadata": {
        "id": "vkIbTIzAyPQK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t = []\n",
        "#a = questions_easy_algebra + answers_easy_algebra"
      ],
      "metadata": {
        "id": "WFzzrWrL3Fx_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a[-4]"
      ],
      "metadata": {
        "id": "9i8rzuUO3K3q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a = get_vocabulary([questions_easy_algebra, answers_easy_algebra])"
      ],
      "metadata": {
        "id": "qLdQ5Ub64D19"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a"
      ],
      "metadata": {
        "id": "t8-fBTK96BjC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import string\n",
        "#a = string.printable"
      ],
      "metadata": {
        "id": "ReFssKsb4S9q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#string.ascii_uppercase"
      ],
      "metadata": {
        "id": "SrE81tMC6X0Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(string.ascii_lowercase) + 10 + ['%', '&', '(', ')', ]"
      ],
      "metadata": {
        "id": "uo7cY2Ch5uV2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a"
      ],
      "metadata": {
        "id": "NsdZzFFW5Igb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tMm3aIe5ESf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(a[:-6]) - len(string.ascii_uppercase)"
      ],
      "metadata": {
        "id": "L1V_7Duz4JiO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#insert <bos>, <eos> and <pad>\n",
        "it = 0\n",
        "questions, answers = [], []\n",
        "seq_len = 256\n",
        "answer_len = 50\n",
        "for qa in train:\n",
        "    q = qa['question']\n",
        "    a = qa['answer']\n",
        "    question = ['<bos>']\n",
        "    answer = ['<bos>']\n",
        "    for i in range(1, len(q) - 1):\n",
        "        question.append(q[i])\n",
        "    while i < seq_len - 1:\n",
        "        question.append('<pad>')\n",
        "        i += 1\n",
        "    question.append('<eos>')\n",
        "    questions.append(question)\n",
        "    for j in range(1, len(a) - 1):\n",
        "        answer.append(a[j])\n",
        "    while j < answer_len - 1:\n",
        "        answer.append('<pad>')\n",
        "        j += 1\n",
        "    answer.append('<eos>')\n",
        "    answers.append(answer)\n",
        "    it += 1\n",
        "    if it % 10000 == 0:\n",
        "        print(f\"iteration {it}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FOKF8rS40H5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8cccca0e-29b2-4d60-f1db-142c9085c23d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#insert <bos>, <eos> and <pad>\\nit = 0\\nquestions, answers = [], []\\nseq_len = 256\\nanswer_len = 50\\nfor qa in train:\\n    q = qa[\\'question\\']\\n    a = qa[\\'answer\\']\\n    question = [\\'<bos>\\']\\n    answer = [\\'<bos>\\']\\n    for i in range(1, len(q) - 1):\\n        question.append(q[i])\\n    while i < seq_len - 1:\\n        question.append(\\'<pad>\\')\\n        i += 1\\n    question.append(\\'<eos>\\')\\n    questions.append(question)\\n    for j in range(1, len(a) - 1):\\n        answer.append(a[j])\\n    while j < answer_len - 1:\\n        answer.append(\\'<pad>\\')\\n        j += 1\\n    answer.append(\\'<eos>\\')\\n    answers.append(answer)\\n    it += 1\\n    if it % 10000 == 0:\\n        print(f\"iteration {it}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list(vocabulary)"
      ],
      "metadata": {
        "id": "4PsBGnw7Pd3U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vocabulary_from_set(voc: set):\n",
        "    vocabulary = {'<bos>': 0, '<eos>': 1, '<unk>': 2, '<pad>': 3}\n",
        "    i = 4\n",
        "    for v in voc:\n",
        "        vocabulary[v] = i\n",
        "        i += 1\n",
        "    return vocabulary"
      ],
      "metadata": {
        "id": "CoqhJC32Oq8l"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = create_vocabulary_from_set(vocabulary)"
      ],
      "metadata": {
        "id": "ovYoSu0pP6vX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def read_dataset(text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    with open(text_path) as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            if lowercase:\n",
        "                if idx % 2 == 0: # Questions\n",
        "                    questions.append(line.rstrip().lower()) \n",
        "                else:\n",
        "                    answers.append(line.rstrip().lower())\n",
        "\n",
        "    return questions, answers\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VVuI58IKLWyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "46bc1c5e-f1d1-47fc-e2bc-083714485765"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef read_dataset(text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\\n    questions = []\\n    answers = []\\n\\n    with open(text_path) as f:\\n        for idx, line in enumerate(f):\\n            if lowercase:\\n                if idx % 2 == 0: # Questions\\n                    questions.append(line.rstrip().lower()) \\n                else:\\n                    answers.append(line.rstrip().lower())\\n\\n    return questions, answers\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Mathematics_Dataset(Dataset):\n",
        "    def __init__(self, modules: List[str], vocabulary: dict):\n",
        "        self.modules = modules\n",
        "        self.questions = []\n",
        "        self.answers = []\n",
        "        for m in self.modules:\n",
        "            q_m, a_m = self.read_dataset(m)\n",
        "            self.questions += q_m\n",
        "            self.answers += a_m\n",
        "        self.max_len_question = 160 #forse serve multiplo di num_heads\n",
        "        self.max_len_answer = 30\n",
        "        self.vocabulary = vocabulary\n",
        "\n",
        "    def read_dataset(self, text_path: str, lowercase: bool=True) -> Tuple[List[str], List[str]]:\n",
        "        questions = []\n",
        "        answers = []\n",
        "        with open(text_path, 'r') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                if lowercase:\n",
        "                    if idx % 2 == 0: # Questions\n",
        "                        questions.append(line.rstrip().lower()) \n",
        "                    else: #Answers\n",
        "                        answers.append(line.rstrip().lower())\n",
        "        return questions, answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert idx < len(self.questions)\n",
        "        q, a = self.questions[idx], self.answers[idx]\n",
        "        question, answer = np.zeros(self.max_len_question + 2), np.zeros(self.max_len_answer + 2) #np.zeros(self.max_len_question + 2) \n",
        "        question[0] = self.vocabulary['<bos>']\n",
        "        answer[0] = self.vocabulary['<bos>']\n",
        "\n",
        "        for i in range(len(q)):\n",
        "            c = '<unk>'\n",
        "            if q[i] in self.vocabulary:\n",
        "                c = q[i]\n",
        "            question[i + 1] = self.vocabulary[c]\n",
        "        i += 1\n",
        "        question[i + 1] = self.vocabulary['<eos>']\n",
        "        i += 1\n",
        "        while i < self.max_len_question + 1:\n",
        "            question[i + 1] = self.vocabulary['<pad>']\n",
        "            i += 1\n",
        "    \n",
        "        for j in range(len(a)):\n",
        "            c = '<unk>'\n",
        "            if a[j] in self.vocabulary:\n",
        "                c = a[j]\n",
        "            answer[j + 1] = self.vocabulary[c]\n",
        "        j += 1\n",
        "        answer[j + 1] = self.vocabulary['<eos>']\n",
        "        j += 1\n",
        "        while j < self.max_len_answer + 1: \n",
        "            answer[j + 1] = self.vocabulary['<pad>']\n",
        "            j += 1\n",
        "        question = torch.from_numpy(question).long()\n",
        "        answer = torch.from_numpy(answer).long()\n",
        "        return question, answer"
      ],
      "metadata": {
        "id": "jTr3UUzxtsvg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BXjVw2SaXUyM",
        "outputId": "eec4415e-92ee-449d-822f-48c3942e35ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Deep_Learning_Project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gfwuILFYWAK",
        "outputId": "8436002c-56c6-4f8c-f10f-32ec74362f44"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algebra__linear_1d  datasets  mathematics_dataset-v1.0\tmodules.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = Mathematics_Dataset(['./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt'], v)"
      ],
      "metadata": {
        "id": "r0Dw7JW2Tdfk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q, a = d.__getitem__(8)"
      ],
      "metadata": {
        "id": "AjWNU26hVsrj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q, a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghYwlKD0hZBf",
        "outputId": "86fa1d75-f02b-4493-925c-f6ed0f1060d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0, 48, 46, 10,  8, 41, 22, 57, 53, 44, 14, 52, 22, 45, 22, 43, 53, 14,\n",
              "         52, 22, 57, 22, 53, 43, 22, 54, 22, 51, 22, 52, 46, 21, 22, 52, 34,  1,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3]),\n",
              " tensor([ 0, 43,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.shape"
      ],
      "metadata": {
        "id": "MwmQpGQHdVX9",
        "outputId": "68b812d5-1988-43ba-c895-c8be20b82352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([162])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Mathematics_DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, modules: List[str], batch_size: int = 32):\n",
        "        super().__init__()\n",
        "        self.modules = modules\n",
        "        self.batch_size = batch_size\n",
        "        self.load_vocabulary()\n",
        "    \n",
        "    def load_vocabulary(self):\n",
        "        with open('./datasets/vocabulary.pkl', 'rb') as f:\n",
        "            v = pickle.load(f)\n",
        "        self.vocabulary = create_vocabulary_from_set(v)\n",
        "\n",
        "    def setup(self):\n",
        "        self.math = Mathematics_Dataset(self.modules, self.vocabulary)\n",
        "        self.math_train, self.math_val, self.math_test = random_split(self.math, [0.75, 0.05, 0.20])\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.math_train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):                                                              \n",
        "        return DataLoader(self.math_val, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.math_test, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def teardown(self, stage: str):\n",
        "        # Used to clean-up when the run is finished\n",
        "        pass"
      ],
      "metadata": {
        "id": "vTNe-ysc94gb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = Mathematics_DataModule(['./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt'], batch_size = 64)"
      ],
      "metadata": {
        "id": "WmwPwXV6cnWm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.setup()"
      ],
      "metadata": {
        "id": "TUnTxKp_diid"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.train_dataloader()"
      ],
      "metadata": {
        "id": "4n0CtcAxdoiz",
        "outputId": "24dd0296-6a21-4bbd-9c55-f685d65a0916",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f5ded88baf0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "i = 0\n",
        "for s in dm.train_dataloader():\n",
        "    print(s)\n",
        "    i += 1\n",
        "    if i == 2:\n",
        "        break\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tTFoTRdndxNG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5b39c2d-8c83-4cf3-ecec-50b57ebd1c86"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni = 0\\nfor s in dm.train_dataloader():\\n    print(s)\\n    i += 1\\n    if i == 2:\\n        break\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "ho9Tk3GctrvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#forse meglio definire una stable softmax\n",
        "\"\"\"\n",
        "la x emb_d @ emb_d x lq\n",
        "la x lq (forse errore perché la maschera è la x la)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tg6p4Y4ZXAyU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58d1e310-b713-450a-8431-58e44e5e6540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nla x emb_d @ emb_d x lq\\nla x lq (forse errore perché la maschera è la x la)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product_attention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    t = t.masked_fill_(mask == False, -1e-10) #-1e-10 acts like -infinity, so that the softmax will consider these tokens less important\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)"
      ],
      "metadata": {
        "id": "9JbWbeOJtt02"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module): \n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, tp_attention = False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert embedding_dim % num_heads == 0\n",
        "        self.tp_attention = tp_attention\n",
        "        self.dim_head = embedding_dim // num_heads #single head dimension\n",
        "        self.sqrt_q = sqrt(self.dim_head)\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.W_q = nn.Linear(embedding_dim, embedding_dim, bias = True) #stack of num_heads matrices of dimension (d, dim_head), one for each head\n",
        "        self.W_k = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_v = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_o = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        if self.tp_attention:\n",
        "            self.W_r = nn.Linear(embedding_dim, embedding_dim, bias = True) #ruolo\n",
        "\n",
        "    def forward(self, query, key, value, mask): #query, key, value\n",
        "        q = self.W_q(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        k = self.W_k(key).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        v = self.W_v(value).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "\n",
        "        attention_value = dot_product_attention(q, k, v, self.sqrt_q, mask)\n",
        "\n",
        "        if self.tp_attention:\n",
        "            role = self.W_r(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "            attention_value *= role  #element-wise product between attention value and role before the final projection\n",
        "        return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.num_heads*self.dim_head))"
      ],
      "metadata": {
        "id": "cdtptdthS6Td"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class TP_MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size):\n",
        "        super(TP_MultiHeadAttention, self).__init__()\n",
        "        assert embedding_dim % num_heads == 0\n",
        "        self.dim_head = embedding_dim // num_heads #single head dimension\n",
        "        self.sqrt_q = sqrt(self.dim_head)\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.W_q = nn.Linear(embedding_dim, embedding_dim, bias = True) #stack of num_heads matrices of dimension (d, dim_head), one for each head\n",
        "        self.W_k = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_v = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "        self.W_o = nn.Linear(embedding_dim, embedding_dim, bias = True)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None): #query, key, value\n",
        "        q = self.W_q(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        k = self.W_k(key).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        v = self.W_v(value).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        role = self.W_r(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
        "        attention_value = dot_product_attention(q, k, v, self.sqrt_q, mask).transpose(1, 2) \n",
        "        return self.W_o((attention_value * role).contiguous().view(self.batch_size, -1, self.num_heads*self.dim_head)) #element-wise product between attention value and role before the final projection\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lEUjRO5EURve",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "47fe5bd5-d920-4f54-faf2-8c9ea6af6fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass TP_MultiHeadAttention(nn.Module):\\n    def __init__(self, embedding_dim, num_heads, batch_size):\\n        super(TP_MultiHeadAttention, self).__init__()\\n        assert embedding_dim % num_heads == 0\\n        self.dim_head = embedding_dim // num_heads #single head dimension\\n        self.sqrt_q = sqrt(self.dim_head)\\n        self.num_heads = num_heads\\n        self.batch_size = batch_size\\n        self.W_q = nn.Linear(embedding_dim, embedding_dim, bias = True) #stack of num_heads matrices of dimension (d, dim_head), one for each head\\n        self.W_k = nn.Linear(embedding_dim, embedding_dim, bias = True)\\n        self.W_v = nn.Linear(embedding_dim, embedding_dim, bias = True)\\n        self.W_o = nn.Linear(embedding_dim, embedding_dim, bias = True)\\n\\n    def forward(self, query, key, value, mask = None): #query, key, value\\n        q = self.W_q(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\\n        k = self.W_k(key).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\\n        v = self.W_v(value).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\\n        role = self.W_r(query).view(self.batch_size, -1, self.num_heads, self.dim_head).transpose(1, 2)\\n        attention_value = dot_product_attention(q, k, v, self.sqrt_q, mask).transpose(1, 2) \\n        return self.W_o((attention_value * role).contiguous().view(self.batch_size, -1, self.num_heads*self.dim_head)) #element-wise product between attention value and role before the final projection\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, hidden_size = None, dropout=0.2, tp_attention = False):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.attention = MultiHeadAttention(embedding_dim, num_heads, batch_size, tp_attention)\n",
        "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        hidden_size = 4*embedding_dim if hidden_size is None else hidden_size\n",
        "        self.ff = nn.Sequential(nn.Linear(embedding_dim, hidden_size, bias = True), \n",
        "                                nn.ReLU(inplace = True),\n",
        "                                nn.Linear(hidden_size, embedding_dim, bias = True))\n",
        "\n",
        "    def forward(self, query, key, value, mask): #query, key, value\n",
        "        x = query + self.attention(query, key, value, mask) #query as res conn because the decoder block requires it and it doesn't matter for encoder blocks\n",
        "        x = self.dropout1(self.norm1(x))\n",
        "        x = x + self.ff(x)\n",
        "        x = self.dropout2(self.norm2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "GhrmQH8sUHwE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, hidden_size, dropout = 0.2, tp_attention = False):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.masked_attention = MultiHeadAttention(embedding_dim, num_heads, batch_size, tp_attention)\n",
        "        self.norm = nn.LayerNorm(embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.transformer_block = TransformerBlock(embedding_dim, num_heads, batch_size, hidden_size, dropout, tp_attention)\n",
        "\n",
        "    def forward(self, output_encoder, src_mask, y, trg_mask):\n",
        "        y = y + self.masked_attention(y, y, y, trg_mask) #masked attention (y = query = key = value) + residual connection\n",
        "        y = self.dropout(self.norm(y))\n",
        "        return self.transformer_block(y, output_encoder, output_encoder, src_mask)#query from the masked mha and key and value from the encoder"
      ],
      "metadata": {
        "id": "w0MIvv-ZWL-M"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_len = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, embedding_dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * -(math.log(10000.0) / embedding_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x + Variable(self.pe[:, :x.size(1)], requires_grad = False)"
      ],
      "metadata": {
        "id": "qrsDFyoyUF0D"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, hidden_size, dropout, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = nn.ModuleList(\n",
        "            [TransformerBlock(embedding_dim, num_heads, batch_size, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, x, mask): \n",
        "        for block in self.encoder:\n",
        "            x = block(x, x, x, mask)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bgNDRuG5YIWz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, hidden_size, dropout = 0.2, num_blocks = 6, tp_attention = False):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.decoder = nn.ModuleList(\n",
        "            [DecoderBlock(embedding_dim, num_heads, batch_size, hidden_size, dropout, tp_attention) for _ in range(num_blocks)]\n",
        "            )\n",
        "\n",
        "    def forward(self, output_encoder, src_mask, y, trg_mask): \n",
        "        for block in self.decoder:\n",
        "            y = block(output_encoder, src_mask, y, trg_mask)\n",
        "        return y"
      ],
      "metadata": {
        "id": "Aybtz4uUY8vQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, embedding_dim, num_heads, batch_size, hidden_size, dropout, vocabulary_size, pad_id = 3, num_blocks_encoder = 6, num_blocks_decoder = 6, tp_attention = False):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.batch_size = batch_size\n",
        "        self.pad_id = pad_id\n",
        "        self.token_embedding = nn.Embedding(vocabulary_size, embedding_dim, padding_idx = self.pad_id)\n",
        "        self.positional_embedding = PositionalEncoding(embedding_dim)\n",
        "        self.encoder = TransformerEncoder(embedding_dim, num_heads, batch_size, hidden_size, dropout, num_blocks_encoder, tp_attention)\n",
        "        self.decoder = TransformerDecoder(embedding_dim, num_heads, batch_size, hidden_size, dropout, num_blocks_decoder, tp_attention)\n",
        "        self.to_logits = nn.Linear(embedding_dim, vocabulary_size)\n",
        "        \n",
        "        self.max_len_question = 162\n",
        "        self.max_len_answer = 32\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=vocabulary_size, ignore_index = self.pad_id)\n",
        "\n",
        "    def create_trg_mask(self, y): #compute a mask so that the prediction of the next token can only depend on the previous tokens\n",
        "        return self.create_causal_mask(y) & self.create_padding_mask(y) #[batch_size, 1, len, len] & [batch_size, 1, 1, len]\n",
        "\n",
        "    def create_causal_mask(self, y):\n",
        "        batch_size, seq_len = y.shape\n",
        "        mask = torch.tril(torch.ones((seq_len, seq_len), dtype = torch.bool)).expand(\n",
        "            batch_size, 1, seq_len, seq_len)\n",
        "        return mask\n",
        "\n",
        "    def create_padding_mask(self, x):\n",
        "        batch_size, seq_len = x.shape\n",
        "        mask = (x != self.pad_id).unsqueeze(-2).unsqueeze(-2).expand(\n",
        "                batch_size, 1, 1, seq_len)\n",
        "        return mask\n",
        "\n",
        "    def inference(self, x):\n",
        "        #encode and then generate the output token by token greedily\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            src_mask = self.create_padding_mask(x)\n",
        "            x = self.token_embedding(x)\n",
        "\n",
        "            x = self.positional_embedding(x)\n",
        "            output_encoder = self.encoder(x, src_mask)\n",
        "            output = torch.ones(x.shape[0], 1).fill_(0).long()# #0 is the <bos> index in the vocabulary\n",
        "            \n",
        "            for _ in range(self.max_len_answer - 1): \n",
        "                trg_mask = self.create_trg_mask(output)\n",
        "                output_embedding = self.token_embedding(output)\n",
        "                output_embedding = self.positional_embedding(output_embedding)\n",
        "                out = self.decoder(output_encoder, src_mask, output_embedding, trg_mask)\n",
        "                out = self.to_logits(out) #[batch, len, vocab_size] [batch, len-1]\n",
        "                out = torch.argmax(out[:,[-1],:], dim = -1)\n",
        "                output = torch.cat([output, out], dim = 1)\n",
        "            return output\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        src_mask = self.create_padding_mask(x)\n",
        "        trg_mask = self.create_trg_mask(y)\n",
        "\n",
        "        x = self.token_embedding(x)\n",
        "        x = self.positional_embedding(x)\n",
        "        y = self.token_embedding(y)\n",
        "        y = self.positional_embedding(y)\n",
        "\n",
        "        output_encoder = self.encoder(x, src_mask)\n",
        "        return self.to_logits(self.decoder(output_encoder, src_mask, y, trg_mask)).transpose(1,2)\n",
        "    \n",
        "    def configure_optimizers(self):# learning rate = 1x10^-4; beta1 =0.9; beta2 = 0.995 dal paper\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4, betas=(0.9, 0.995))\n",
        "\n",
        "    def training_step(self, batch, batch_idx): #aggiungi gradient clipping nel Trainer\n",
        "        x, y = batch\n",
        "        y_pred = self(x, y)\n",
        "        loss = F.cross_entropy(y_pred, y, ignore_index = self.pad_id)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_pred = self.inference(x) #controlla che sia [batch_size, vocabulary_size, question_len]\n",
        "        self.accuracy.update(y_pred, y)\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.log('accuracy_epoch', self.accuracy.compute())\n",
        "        self.accuracy.reset()\n"
      ],
      "metadata": {
        "id": "qiPC8tqNY8wN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm = Mathematics_DataModule(['./mathematics_dataset-v1.0/train-easy/algebra__linear_1d.txt'], batch_size = 8)"
      ],
      "metadata": {
        "id": "56kHXNBlOAWW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm.setup()\n",
        "dl = dm.train_dataloader()"
      ],
      "metadata": {
        "id": "tToexCz3OQb8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dl))\n",
        "(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "7azh03qfFifN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b44d5b-728d-497d-d592-9eb9d26398fb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 162]), torch.Size([8, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = Transformer(256, 4, 8, 256, 0.2, 58)"
      ],
      "metadata": {
        "id": "4_Enun2AOfOp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1.inference(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u61AZqgoyYi",
        "outputId": "282e0680-277a-421f-f428-57092ba81257"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape prima di token_embedding torch.Size([8, 162])\n",
            "src_mask.shape torch.Size([8, 1, 1, 162])\n",
            "x.shape dopo token_embedding torch.Size([8, 162, 256])\n",
            "x.shape dopo positional_embedding torch.Size([8, 162, 256])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "output_encoder.shape torch.Size([8, 162, 256])\n",
            "INIZIO OUTPUT\n",
            "shape output: torch.Size([8, 1])\n",
            "create_causal_mask\n",
            "  shape y torch.Size([8, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "shape causal mask: torch.Size([8, 1, 1, 1])\n",
            "shape padding mask: torch.Size([8, 1, 1, 1])\n",
            "shape tgr_mask: torch.Size([8, 1, 1, 1])\n",
            "output.shape prima di token_embedding torch.Size([8, 1])\n",
            "output_embedding.shape torch.Size([8, 1, 256])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 1, 1])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 1, 64])\n",
            "  shape t torch.Size([8, 4, 1, 1])\n",
            "  shape mask torch.Size([8, 1, 1, 1])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 1, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 1, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 1, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 1, 64])\n",
            "logits shape: torch.Size([8, 1, 58])\n",
            "out shape: torch.Size([8, 1])\n",
            "output shape: torch.Size([8, 2])\n",
            "shape output: torch.Size([8, 2])\n",
            "create_causal_mask\n",
            "  shape y torch.Size([8, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "shape causal mask: torch.Size([8, 1, 2, 2])\n",
            "shape padding mask: torch.Size([8, 1, 1, 2])\n",
            "shape tgr_mask: torch.Size([8, 1, 2, 2])\n",
            "output.shape prima di token_embedding torch.Size([8, 2])\n",
            "output_embedding.shape torch.Size([8, 2, 256])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 2, 2])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 2, 64])\n",
            "  shape t torch.Size([8, 4, 2, 2])\n",
            "  shape mask torch.Size([8, 1, 2, 2])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 2, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 2, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 2, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 2, 64])\n",
            "logits shape: torch.Size([8, 2, 58])\n",
            "out shape: torch.Size([8, 1])\n",
            "output shape: torch.Size([8, 3])\n",
            "shape output: torch.Size([8, 3])\n",
            "create_causal_mask\n",
            "  shape y torch.Size([8, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "shape causal mask: torch.Size([8, 1, 3, 3])\n",
            "shape padding mask: torch.Size([8, 1, 1, 3])\n",
            "shape tgr_mask: torch.Size([8, 1, 3, 3])\n",
            "output.shape prima di token_embedding torch.Size([8, 3])\n",
            "output_embedding.shape torch.Size([8, 3, 256])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 3, 3])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 3, 64])\n",
            "  shape t torch.Size([8, 4, 3, 3])\n",
            "  shape mask torch.Size([8, 1, 3, 3])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 3, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 3, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 3, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 3, 64])\n",
            "logits shape: torch.Size([8, 3, 58])\n",
            "out shape: torch.Size([8, 1])\n",
            "output shape: torch.Size([8, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 24, 22, 26],\n",
              "        [ 0, 24, 22, 26],\n",
              "        [ 0, 24, 22, 26],\n",
              "        [ 0, 24, 22, 26],\n",
              "        [ 0, 24, 24, 22],\n",
              "        [ 0, 24, 22, 26],\n",
              "        [ 0, 24, 22, 26],\n",
              "        [ 0, 24, 22, 26]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1(x, y).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "756pOhA-O8bg",
        "outputId": "ff903cbf-5547-4993-ea89-191cd459d9b5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_causal_mask\n",
            "  shape y torch.Size([8, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 58, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(t1(x, y), y, ignore_index = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5zaBbbBlj-P",
        "outputId": "5a9d72d8-a47d-4f86-f9b6-7768c8b1facc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_causal_mask\n",
            "  shape y torch.Size([8, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.4603, grad_fn=<NllLoss2DBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=58, ignore_index = 3)\n",
        "accuracy.update(t1(x, y), y)"
      ],
      "metadata": {
        "id": "Dj-h9Kchl6Zl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5cc4bf-e548-4cb6-930e-5d7ef6af4364"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create_causal_mask\n",
            "  shape y torch.Size([8, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 162, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 162, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 162, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 162, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "trg_mask.shape torch.Size([8, 1, 32, 32])\n",
            "self_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 32, 64])\n",
            "  shape t torch.Size([8, 4, 32, 32])\n",
            "  shape mask torch.Size([8, 1, 32, 32])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n",
            "src_attn\n",
            "forward\n",
            "q,k,v.shape torch.Size([8, 4, 32, 64])\n",
            "dot_product_attention\n",
            "  shape query torch.Size([8, 4, 32, 64])\n",
            "  shape key torch.Size([8, 4, 162, 64])\n",
            "  shape t torch.Size([8, 4, 32, 162])\n",
            "  shape mask torch.Size([8, 1, 1, 162])\n",
            "attention_value.shape torch.Size([8, 4, 32, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = Transformer(128, 4, 8, 256, 0.2, 58, tp_attention = True)"
      ],
      "metadata": {
        "id": "nsAWmtgiO8f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2(x,y)"
      ],
      "metadata": {
        "id": "9Fsh86VfUenO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOTA"
      ],
      "metadata": {
        "id": "sEka3B3Eq69g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uf3QJeF-q-AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NON-SOTA"
      ],
      "metadata": {
        "id": "0b4LEKhjtizS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mm-mxAgbtmPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}